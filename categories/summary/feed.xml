<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>summary on Nicholas M. Synovic</title><link>https://nsynovic.dev/categories/summary/</link><description>Recent content in summary on Nicholas M. Synovic</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Nicholas M. Synovic</copyright><lastBuildDate>Wed, 09 Nov 2022 15:17:53 -0600</lastBuildDate><atom:link href="https://nsynovic.dev/categories/summary/feed.xml" rel="self" type="application/rss+xml"/><item><title>A summary of The Random Subspace Method for Constructing Decision Forests by Tin Kam Ho</title><link>https://nsynovic.dev/summaries/the-random-subspace-method-for-constructing-decision-forests/</link><pubDate>Wed, 09 Nov 2022 15:17:53 -0600</pubDate><guid>https://nsynovic.dev/summaries/the-random-subspace-method-for-constructing-decision-forests/</guid><description>&lt;h1 id="a-summary-of-the-random-subspace-method-for-constructing-decision-forests">A summary of &lt;em>The Random Subspace Method for Constructing Decision Forests&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Tin Kam Ho, IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,
1998 &lt;a href="https://doi.org/10.1109/34.709601">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-the-random-subspace-method-for-constructing-decision-forests">A summary of &lt;em>The Random Subspace Method for Constructing Decision Forests&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#problem">Problem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#methodology">Methodology&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#open-questions">Open Questions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-feedback">Author Feedback&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Read the title, abstract, introduction, section and sub-section headings, and
conclusion&lt;/p>
&lt;/blockquote>
&lt;h3 id="problem">Problem&lt;/h3>
&lt;blockquote>
&lt;p>What is the problem addressed in the paper?&lt;/p>
&lt;/blockquote>
&lt;p>This paper addresses the problem of decision tree forest construction.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this paper as it compares eight forest construction
algorithms against the author&amp;rsquo;s algorithm on publicly available datasets. This
allows the reader to understand the pros and cons of using a particular
algorithm over another as well as validating the author&amp;rsquo;s claims. Furthermore,
this algorithm can monotonically increase in generalization accuracy while
preserving perfect accuracy.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is an algorithms paper.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is related to papers that present ways of constructing random
forests.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Her main contributions were:&lt;/p>
&lt;ul>
&lt;li>An efficient algorithm for generating decision trees&lt;/li>
&lt;li>A comparison of 8 forest construction algorithms on publicly available
datasets&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;blockquote>
&lt;p>A proper read through of the paper is required to answer this&lt;/p>
&lt;/blockquote>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done before to describe what decision trees are, as well as how to
generate many of them for the purposes of classification.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the tables are clear and easy to read. However, all of the line charts
are difficult to read as each line is the same color in my copy of the paper.
Additionally, figure 1 is difficult to tell what is supposed to represented.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>I found this work hard to follow. I think that this is due to me not
understanding the problem domain, rather than her explanations.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ol start="2">
&lt;li>Y. Amit, D. Geman, and K. Wilder, “&lt;em>Joint Induction of Shape Features and
Tree Classifiers&lt;/em>,” IEEE Trans. Pattern Analysis and Machine Intelligence,
vol. 19, no. 11, pp. 1,300-1,305, Nov. 1997&lt;/li>
&lt;li>L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone, &lt;em>Classification and
Regression Trees&lt;/em>. Belmont, Calif.: Wadsworth, 1984&lt;/li>
&lt;li>D. Heath, S. Kasif, and S. Salzberg, “&lt;em>Induction of Oblique Decision Trees&lt;/em>,”
Proc. 13th Int’l Joint Conf. Artificial Intelligence, vol. 2, pp.
1,002-1,007, Chambery, France, 28 Aug.-3 Sept. 1993.&lt;/li>
&lt;li>T.K. Ho, “Random Decision Forests,” Proc. Third Int’l Conf. Document Analysis
and Recognition, pp. 278-282, Montreal, Canada, 14-18 Aug. 1995.&lt;/li>
&lt;li>T.K. Ho, “C4.5 Decision Forests,” Proc. 14th Int’l Conf. Pattern Recognition,
Brisbane, Australia, 17-20 Aug. 1998.&lt;/li>
&lt;/ol>
&lt;h3 id="methodology">Methodology&lt;/h3>
&lt;blockquote>
&lt;p>What methodology did the author&amp;rsquo;s use to validate their contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The author compared the performance of different forest generation methods
against her own generation method. The different forest generation methods were:&lt;/p>
&lt;ul>
&lt;li>Single feature split with best gain ratio&lt;/li>
&lt;li>Distribution mapping&lt;/li>
&lt;li>Class centroids&lt;/li>
&lt;li>Unsupervised clustering&lt;/li>
&lt;li>Supervised clustering&lt;/li>
&lt;li>Central axis projection&lt;/li>
&lt;li>Perceptron&lt;/li>
&lt;li>Support Vector Machine&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The author assumes that the reader has worked with decision trees prior to
reading.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>Yes.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d like to learn more about decision trees and compare them against Deep
Learning models.&lt;/p>
&lt;h3 id="open-questions">Open Questions&lt;/h3>
&lt;blockquote>
&lt;p>What open questions do I have about the work?&lt;/p>
&lt;/blockquote>
&lt;p>When would I ever use a decision tree over a SVM or DL model?&lt;/p>
&lt;h3 id="author-feedback">Author Feedback&lt;/h3>
&lt;blockquote>
&lt;p>What feedback would I give to the authors?&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d appreciate the usage of color to separate different lines on the figures.
Additionally (and this could be due to the limited available citation), please
reduce the number of self-citations in future works.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>The Random Subspace Method for Constructing Decision Forests&lt;/em> by Tin
Kam Ho [1] discusses a method of generating many decision trees efficiently
without affecting accuracy. She validates this method by comparing it against
eight other forest construction methods, all on publicly available datasets. The
benefits of her work is that it is parallelized; meaning that with some tuning
to the algorithm, it can run on multiple CPU cores or threads (potentially even
faster on GPU cores).&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/the-random-subspace-method-for-constructing-decision-forests/</description></item><item><title>A summary of Deep Learning by Yann LeCun et al,</title><link>https://nsynovic.dev/summaries/deep-learning/</link><pubDate>Tue, 08 Nov 2022 12:55:10 -0600</pubDate><guid>https://nsynovic.dev/summaries/deep-learning/</guid><description>&lt;h1 id="a-summary-of-deep-learning">A summary of &lt;em>Deep Learning&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Yann LeCunn et al, Nature, 2015 &lt;a href="https://doi.org/10.1038/nature14539">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-deep-learning">A summary of &lt;em>Deep Learning&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#problem">Problem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#methodology">Methodology&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#open-questions">Open Questions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-feedback">Author Feedback&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Read the title, abstract, introduction, section and sub-section headings, and
conclusion&lt;/p>
&lt;/blockquote>
&lt;h3 id="problem">Problem&lt;/h3>
&lt;blockquote>
&lt;p>What is the problem addressed in the paper?&lt;/p>
&lt;/blockquote>
&lt;p>This paper discusses the usage of deep learning (DL) models and how they have
led to improvements in speech recognition, visual object recognition, object
detection, drug discovery, and genomics. It talks about how these models are
created, what type of models are typically applied to what domains, and the
usage of the backpropagation algorithm to train the model. Additionally, a
discussion about the usage of Recurrent Neural Networks (RNNs) and their
benefits is had.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this paper as it is a review of different DL techniques for
different problem domains.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is a literary review paper.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>It is closest related to papers that summarize a body of literature for the
purposes of understanding what the current SOTA techniques for a problem are.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their main contribution is a discussion of DL, its usages, RNNs, and a general
summary of the SOTA DL techniques for different problem domains.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;blockquote>
&lt;p>A proper read through of the paper is required to answer this&lt;/p>
&lt;/blockquote>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done to develop DL and RNN techniques.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the figures are clear and easy to understand.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is well written.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ol start="2">
&lt;li>Krizhevsky, A., Sutskever, I. &amp;amp; Hinton, G. &lt;em>ImageNet classification with
deep convolutional neural networks.&lt;/em> In Proc. Advances in Neural Information
Processing Systems 25 1090–1098 (2012).&lt;/li>
&lt;li>Hinton, G. et al. &lt;em>Deep neural networks for acoustic modeling in speech&lt;/em>
recognition. IEEE Signal Processing Magazine 29, 82–97 (2012).&lt;/li>
&lt;li>Sutskever, I. Vinyals, O. &amp;amp; Le. Q. V. &lt;em>Sequence to sequence learning with
neural&lt;/em> networks. In Proc. Advances in Neural Information Processing Systems
27 3104–3112 (2014)&lt;/li>
&lt;li>Glorot, X., Bordes, A. &amp;amp; Bengio. Y. &lt;em>Deep sparse rectifier neural networks.&lt;/em>
In Proc. 14th International Conference on Artificial Intelligence and
Statistics 315–323 (2011).&lt;/li>
&lt;li>Hinton, G. E., Osindero, S. &amp;amp; Teh, Y.-W. &lt;em>A fast learning algorithm for deep
belief nets&lt;/em>. Neural Comp. 18, 1527–1554 (2006).&lt;/li>
&lt;li>Bengio, Y., Lamblin, P., Popovici, D. &amp;amp; Larochelle, H. &lt;em>Greedy layer-wise
training of deep networks.&lt;/em> In Proc. Advances in Neural Information
Processing Systems 19 153–160 (2006).&lt;/li>
&lt;li>LeCun, Y. et al. &lt;em>Handwritten digit recognition with a back-propagation
network.&lt;/em> In Proc. Advances in Neural Information Processing Systems 396–404
(1990).&lt;/li>
&lt;li>LeCun, Y., Bottou, L., Bengio, Y. &amp;amp; Haffner, P. G&lt;em>radient-based learning
applied to document recognition&lt;/em>. Proc. IEEE 86, 2278–2324 (1998).&lt;/li>
&lt;li>Hochreiter, S. &amp;amp; Schmidhuber, J. &lt;em>Long short-term memory&lt;/em>. Neural Comput. 9,
1735–1780 (1997).&lt;/li>
&lt;/ol>
&lt;h3 id="methodology">Methodology&lt;/h3>
&lt;blockquote>
&lt;p>What methodology did the author&amp;rsquo;s use to validate their contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s of this paper reviewed literary sources for examples and usage of
DL and RNN techniques applied to different problem domains.&lt;/p>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s assume that unsupervised learning will become far more important in
the future than supervised learning.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>Potentially. Unsupervised learning presents problems and challenges not explored
in this paper, and is therefore treated as the next logical evolution of
techniques, rather than a series of unknowns and problems that need to be solved
first.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d like to implement the different DL techniques to the suggested problem
domains presented in this paper.&lt;/p>
&lt;h3 id="open-questions">Open Questions&lt;/h3>
&lt;blockquote>
&lt;p>What open questions do I have about the work?&lt;/p>
&lt;/blockquote>
&lt;p>Why wasn&amp;rsquo;t a discussion about Generative Adversarial Networks (GANs) not had in
this work? What are the performance differences of the presented loss functions?&lt;/p>
&lt;h3 id="author-feedback">Author Feedback&lt;/h3>
&lt;blockquote>
&lt;p>What feedback would I give to the authors?&lt;/p>
&lt;/blockquote>
&lt;p>Overall, a pretty good paper. A follow up paper on unsupervised learning would
be nice to read.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The review paper &lt;em>Deep Learning&lt;/em> by Yann LeCun et al [1]. discusses the
advances and advantages of deep learning (DL) techniques made up to 2015. The
authors discuss what is DL, how and where it is applied, commercial and academic
usages of DL, the advantages of merging two different architectures together to
solve challenging tasks, and the usage of Recurrent Neural Networks (RNNs) for
handling natural language processing and speech recognition tasks. As their
paper is purely a listing of work that others have done prior to them, their
contributions were mostly the synthesis of such information into a digestible
document. With that said, each section of their work can be summarized, which is
what I have done here.&lt;/p>
&lt;p>DL allows for machine learning to surpass its previous limitations of having to
manually represent data in a suitable internal representation (through feature
extraction) by learning the representation itself. Current DL models are
typically trained using labeled datasets in what is known as supervised
learning. A sub-set of the data is used for training, which when ran through the
model, adjusts the hidden weights. These weights are adjusted using a technique
called stochastic gradient descent (SGD). SGD is accomplished by working
backwards through the model and taking the derivative of each weight which is
then used to adjust the hidden weights. Algorithms to do this include &lt;code>tanh(x)&lt;/code>
and &lt;code>ReLU&lt;/code>. &lt;code>ReLU&lt;/code> is the most popular algorithm for this task which is more
commonly known as backpropagation.&lt;/p>
&lt;p>Convolutional neural networks (ConvNets) are useful for analyzing data
structured as a series of multi-dimensional arrays. A typical application of
ConvNets are for analyzing images. RNNs are useful for analyzing data that is
dependent upon prior understanding. Chat bots, speech recognition, and answering
questions about data (i.e where is a character in a book?) are all problems that
are reliant upon the model having some sort of &amp;ldquo;memory&amp;rdquo;. Memory solutions
include &lt;code>long short-term memory&lt;/code> which has been useful for accomplishing these
tasks.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/deep-learning/</description></item><item><title>A summary of Small World with High Risks: A Study of Security Threats in the npm Ecosystem by Markus Zimmermann et al.</title><link>https://nsynovic.dev/summaries/small-world-with-high-risks-a-study-of-security-threats-in-the-npm-ecosystem/</link><pubDate>Wed, 02 Nov 2022 22:49:58 -0500</pubDate><guid>https://nsynovic.dev/summaries/small-world-with-high-risks-a-study-of-security-threats-in-the-npm-ecosystem/</guid><description>&lt;h1 id="a-summary-of-small-world-with-high-risks-a-study-of-security-threats-in-the-npm-ecosystem">A summary of &lt;em>Small World with High Risks: A Study of Security Threats in the npm Ecosystem&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Markus Zimmermann et al. 28th USENIX Security Symposium; 2019
&lt;a href="https://www.usenix.org/conference/usenixsecurity19/presentation/zimmerman">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-small-world-with-high-risks-a-study-of-security-threats-in-the-npm-ecosystem">A summary of &lt;em>Small World with High Risks: A Study of Security Threats in the npm Ecosystem&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#problem">Problem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#methodology">Methodology&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#open-questions">Open Questions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-feedback">Author Feedback&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Read the title, abstract, introduction, section and sub-section headings, and
conclusion&lt;/p>
&lt;/blockquote>
&lt;h3 id="problem">Problem&lt;/h3>
&lt;blockquote>
&lt;p>What is the problem addressed in the paper?&lt;/p>
&lt;/blockquote>
&lt;p>This paper analyzes the security risks that the &lt;code>npm&lt;/code> package manager exposes
end users to directly and indirectly through dependency analysis.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>The 2016 &lt;code>left-pad&lt;/code> and 2018 &lt;code>eslint-scope&lt;/code> caused many dependent packages to
become exposed to security vulnerabilities after being taken down and
compromised respectfully.&lt;/p>
&lt;p>Additionally (and quoted from the paper):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-md" data-lang="md">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> Installing an average npm package introduces an implicit trust on 79
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>third-party packages and 39 maintainers, creating a surprisingly large attack
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>surface.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> Highly popular packages directly or indirectly influence many other packages
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(often more than 100,000) and are thus potential targets for injecting malware.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> Some maintainers have an impact on hundreds of thousands of packages. As a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>result, a very small number of compromised maintainer accounts suffices to
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>inject malware into the majority of all packages.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> The influence of individual packages and maintainers has been continuously
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>growing over the past few years, aggravating the risk of malware injection
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>attacks.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> A significant percentage (up to 40%) of all packages depend on code with at
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>least one publicly known vulnerability.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is a security paper with particular focus on security analysis of software
supply chains.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>Papers that analyze and quantify the risks to software hosting platforms/
software ecosystems. Additionally, papers that discuss the threat models of
software ecosystems are also related.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their main contributions can be found in &lt;a href="#motivation">Motivation&lt;/a>. More
generally, they show that &lt;code>npm&lt;/code> is small in that packages are tightly dependent
upon one another, and that a single security vulnerability is enough to
seriously cripple the functionality of the ecosystem. Furthermore, they analyze
the different threat models to &lt;code>npm&lt;/code>, as well as the role of maintainers with
respect to the wider ecosystem. In addition, they propose several different
mitigations for their proposed threat models. These include:&lt;/p>
&lt;ul>
&lt;li>a vetting process to create &amp;ldquo;trusted&amp;rdquo; maintainers&lt;/li>
&lt;li>a vetting process to analyze newly contributed code of specific packages&lt;/li>
&lt;/ul>
&lt;p>If both process were to be created for a single package, that package would be
considered to have, &amp;ldquo;perfect first-party security&amp;rdquo;. And if this was to be
extended to all transitive packages of that sole package, then it would be
considered to have &amp;ldquo;perfect third-party security&amp;rdquo; If both of the considerations
were to be met, then the package would be considered to be a &amp;ldquo;fully secured
package&amp;rdquo;.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;blockquote>
&lt;p>A proper read through of the paper is required to answer this&lt;/p>
&lt;/blockquote>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done understanding the usage of &amp;ldquo;micro packages&amp;rdquo;, or packages that
accomplish a small functionality.&lt;/p>
&lt;p>Work has been done to understand the server and client security vulnerabilities
in JavaScript.&lt;/p>
&lt;p>Work has been done to understand software ecosystems and to raise questions that
need to be answered with respect to understanding the evolution of the
ecosystems.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the figures are clearly made, as well as well captioned.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is well written and dense. I do wonder if this paper could have been
broken up into potentially two smaller papers. But at the same time, if the
author&amp;rsquo;s were to do that, it might be hard to justify the overall contribution
of the work per paper.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Revisiting software ecosystems research: A longitudinal literature study [2]&lt;/li>
&lt;li>Challenges in software ecosystems research [3]&lt;/li>
&lt;li>An ecosystem and socio-technical view on software maintenance and evolution
[4]&lt;/li>
&lt;li>A look at the dynamics of the JavaScript package ecosystem [5]&lt;/li>
&lt;li>Structure and evolution of package dependency networks [6]&lt;/li>
&lt;li>An empirical comparison of dependency network evolution in seven software
packaging ecosystems [7]&lt;/li>
&lt;li>The evolution of the R software ecosystem [8]&lt;/li>
&lt;li>The evolution of project inter-dependencies in a software ecosystem: The case
of Apache [9]&lt;/li>
&lt;li>Gentoo package dependencies over time [10]&lt;/li>
&lt;/ul>
&lt;h3 id="methodology">Methodology&lt;/h3>
&lt;blockquote>
&lt;p>What methodology did the author&amp;rsquo;s use to validate their contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s used &lt;code>npm&lt;/code> package metadata from 2011 to April of 2018 to generate
several graphs of how packages are related to one another. Following this, they
then utilized graph metrics to measure the potential vulnerabilities &lt;code>npm&lt;/code> is
exposed to, as well as the actual reach of vulnerable packages within &lt;code>npm&lt;/code>.
Additionally, they utilized the package metadata to visualize and understand the
growth of &lt;code>npm&lt;/code> year over year. They utilized these metrics to understand how
potentially dangerous their proposed threat models are to engineers who use
&lt;code>npm&lt;/code>.&lt;/p>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s assume that all proposed threat models are of the same concern. For
some engineers, different models can be of different levels of concern.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>Yes, as this would have involved a survey of engineers to understand&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>While the study of &lt;code>npm&lt;/code> is useful as it is the world&amp;rsquo;s largest software package
ecosystem, I&amp;rsquo;d like to apply the metrics implemented in this work to
understanding PTM software ecosystems, such as Hugging Face and PyTorch Hub.&lt;/p>
&lt;h3 id="open-questions">Open Questions&lt;/h3>
&lt;blockquote>
&lt;p>What open questions do I have about the work?&lt;/p>
&lt;/blockquote>
&lt;p>Will the author&amp;rsquo;s perform a survey to understand if developers feel like the
proposed threat models are feasible?&lt;/p>
&lt;p>What is the &lt;code>npm&lt;/code> community&amp;rsquo;s opinion on reducing the number of micro packages
hosted on &lt;code>npm&lt;/code>?&lt;/p>
&lt;h3 id="author-feedback">Author Feedback&lt;/h3>
&lt;blockquote>
&lt;p>What feedback would I give to the authors?&lt;/p>
&lt;/blockquote>
&lt;p>This work is very interesting and allows for easy expansion and exploration into
other software ecosystems. I suggest to make their graphs publicly available, as
well as to submit the graph to services such as Snyk so that they can further
analyze the data for security concerns (if they haven&amp;rsquo;t already).&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Small World with High Risks: A Study of Security Threats in the npm
Ecosystem&lt;/em> by Markus Zimmermann et al. [1] was a large scale study on &lt;code>npm&lt;/code>
packages and package dependencies taken from 2011 to April 2018. This study was
done to understand the various different threat models that exist on &lt;code>npm&lt;/code> as
well as to understand how &lt;code>npm&lt;/code> has evolved. By studying the evolution of &lt;code>npm&lt;/code>,
the author&amp;rsquo;s were able to analyze the growth of potentially vulnerable software
that can be affected by the proposed threat models. These threat models target
the underlying software package supply chain, and as &lt;code>npm&lt;/code> is considered to be a
small world (packages are tightly coupled to one another often resulting in long
chains), their are high risks involved when a single package is compromised, as
potentially countless more are affected by it.&lt;/p>
&lt;p>The author&amp;rsquo;s main contributions were (taken from the paper):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-md" data-lang="md">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> Installing an average npm package introduces an implicit trust on 79
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>third-party packages and 39 maintainers, creating a surprisingly large attack
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>surface.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> Highly popular packages directly or indirectly influence many other packages
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(often more than 100,000) and are thus potential targets for injecting malware.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> Some maintainers have an impact on hundreds of thousands of packages. As a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>result, a very small number of compromised maintainer accounts suffices to
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>inject malware into the majority of all packages.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> The influence of individual packages and maintainers has been continuously
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>growing over the past few years, aggravating the risk of malware injection
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>attacks.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">-&lt;/span> A significant percentage (up to 40%) of all packages depend on code with at
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>least one publicly known vulnerability.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In addition, they propose several different mitigations for their proposed
threat models. These include:&lt;/p>
&lt;ul>
&lt;li>a vetting process to create &amp;ldquo;trusted&amp;rdquo; maintainers&lt;/li>
&lt;li>a vetting process to analyze newly contributed code of specific packages&lt;/li>
&lt;/ul>
&lt;p>If both process were to be created for a single package, that package would be
considered to have, &amp;ldquo;perfect first-party security&amp;rdquo;. And if this was to be
extended to all transitive packages of that sole package, then it would be
considered to have &amp;ldquo;perfect third-party security&amp;rdquo; If both of the considerations
were to be met, then the package would be considered to be a &amp;ldquo;fully secured
package&amp;rdquo;.&lt;/p>
&lt;p>The threat models that the author&amp;rsquo;s identified were:&lt;/p>
&lt;ul>
&lt;li>Malicious packages&lt;/li>
&lt;li>Exploiting Unmaintained Legacy Code&lt;/li>
&lt;li>Package Takeover&lt;/li>
&lt;li>Account Takeover&lt;/li>
&lt;li>Collusion Attacks&lt;/li>
&lt;/ul>
&lt;p>They found that:&lt;/p>
&lt;ul>
&lt;li>The number of maintainers on &lt;code>npm&lt;/code> is growing significantly slower than the
number of released packages. In other words, maintainers are creating more and
more packages and are there by creating a larger and larger threat space for
an attacker to execute an Account or Package Takeover attack.&lt;/li>
&lt;li>That packages on &lt;code>npm&lt;/code> have a linear growth of direct dependencies, but a
super linear growth of transitive dependencies&lt;/li>
&lt;li>That the average package reach is growing at an exponential rate year over
year&lt;/li>
&lt;li>That there is growth in implicitly trusting maintainers&lt;/li>
&lt;li>That there is fairly linear growth in the number of unpatched advisories year
over year&lt;/li>
&lt;li>That the rate at which published vulnerabilities per 10,000 packages has been
rapidly increasing year over year.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/small-world-with-high-risks-a-study-of-security-threats-in-the-npm-ecosystem/</description></item><item><title>A summary of "What are Weak Links in the npm Supply Chain?", by Nusrat Zahan et al.</title><link>https://nsynovic.dev/summaries/what-are-weak-links-in-the-npm-supply-chain/</link><pubDate>Mon, 31 Oct 2022 09:50:49 -0500</pubDate><guid>https://nsynovic.dev/summaries/what-are-weak-links-in-the-npm-supply-chain/</guid><description>&lt;h1 id="a-summary-of-what-are-weak-links-in-the-npm-supply-chain">A summary of &lt;em>&amp;ldquo;What are Weak Links in the npm Supply Chain?&amp;rdquo;&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Nusrat Zahan et al.; Proceedings of ICSE-SEIP 2022;
&lt;a href="https://doi.org/10.1145/3510457.3513044">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-what-are-weak-links-in-the-npm-supply-chain">A summary of &lt;em>&amp;ldquo;What are Weak Links in the npm Supply Chain?&amp;rdquo;&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#problem">Problem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#methodology">Methodology&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#open-questions">Open Questions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-feedback">Author Feedback&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Read the title, abstract, introduction, section and sub-section headings, and
conclusion&lt;/p>
&lt;/blockquote>
&lt;h3 id="problem">Problem&lt;/h3>
&lt;blockquote>
&lt;p>What is the problem addressed in the paper?&lt;/p>
&lt;/blockquote>
&lt;p>Supply chain attacks stem from a data-driven approach where malicious actors
analyze signals in packages to identify weak links that can be exploited through
the insertion of malicious code. These attacks propagate through the supply
chain and affect unsuspecting users who rely on packages dependent upon the
compromised package.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Reports indicate that in 2021 supply chain attacks increased by 650%. An example
supply chain attack that crippled significant infrastructure was the SolarWinds
attack, which affected 425 Fortune 500 companies and several U.S. federal
agencies. Attacks on the supply chain stem from a data-driven approach, where
attackers analyze package metadata to identify which packages are most
vulnerable based on several signals, and then insert malicious code into the
package. This malicious code then propagates through the supply chain, thereby
affecting many unsuspecting downstream users. The more signals a package has,
the weaker it is considered to be within the supply chain - thereby earning the
name: &amp;ldquo;weak link&amp;rdquo;. Weak links exposes a package to a higher risk of a supply
chain attack and an attacker can exploit signals to execute a supply chain
attack.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is similar to a bug study in that it proposes classifications for
weak link signals. It also is a survey paper, as 470 &lt;code>npm&lt;/code> package maintainers
were interviewed to identify if weak link signals are of importance.
Additionally, this paper proposes a framework for identifying weak link packages
as well.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is similar to papers that study supply chain vulnerabilities, &lt;code>npm&lt;/code>
analysis papers, MSR papers, and developer survey papers.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The authors contributions are:&lt;/p>
&lt;ul>
&lt;li>A proposal of six weak link signals based on an empirical study of 1.63
million &lt;code>npm&lt;/code> packages (91% of all packages on &lt;code>npm&lt;/code> as of 2021)&lt;/li>
&lt;li>A survey of how &lt;code>npm&lt;/code> package maintainers perceive the proposed weak link
signals
&lt;ul>
&lt;li>Three of which were considered to be &lt;strong>strong&lt;/strong> signals by the maintainers&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Eight new signals suggested by the surveyed maintainers&lt;/li>
&lt;li>A framework to collect, categorize, and analyze package metadata in &lt;code>npm&lt;/code> to
evaluate weak link signals&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;blockquote>
&lt;p>A proper read through of the paper is required to answer this&lt;/p>
&lt;/blockquote>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done to define supply chain attacks:&lt;/p>
&lt;ul>
&lt;li>Supply Chain Attack: &amp;ldquo;A supply chain attack is a cyber-attack that aims to
infect organizations and end-users by targeting less-secure components in the
supply chain&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>Work has been done to define supply chain attacks:&lt;/p>
&lt;ul>
&lt;li>Malicious package release&lt;/li>
&lt;li>Social Engineering: Getting a maintainer to hand over sensitive information&lt;/li>
&lt;li>Account Takeover: Taking over an account to inject malicious code under the
maintainer&amp;rsquo;s name&lt;/li>
&lt;li>Ownership Transfer: Taking over an abandoned package&lt;/li>
&lt;li>Remote Execution: Taking over a package by compromising its dependencies&lt;/li>
&lt;/ul>
&lt;p>Work has been done to identify that supply chain attacks are a real threat, and
that no proposed framework is all-encompassing to prevent these attacks from
occurring.&lt;/p>
&lt;p>Work has been done to identify that the human element of package management
(maintainer and contributor information) is the most likely vector to attack.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>The figures and charts are properly labeled, and are clear to read and
understand.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is clear to read, however, there are numerous grammatical errors that
are throughout the paper (punctuation and capitalization errors).&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Does distributed development affect software quality? an empirical case study
of windows vista [2]&lt;/li>
&lt;li>Don’t touch my code! Examining the effects of ownership on software quality
[3]&lt;/li>
&lt;li>SolarWinds attack explained: And why it was so hard to detect [4]&lt;/li>
&lt;li>The Hijacking of Perl.com [5]&lt;/li>
&lt;li>Towards Measuring Supply Chain Attacks on Package Managers for Interpreted
Languages [6]&lt;/li>
&lt;li>Detecting suspicious package updates [7]&lt;/li>
&lt;li>Anomalicious: Automated Detection of Anomalous and Potentially Malicious
Commits on GitHub [8]&lt;/li>
&lt;li>SolarWinds Orion Security Breach: A Shift In The Software Supply Chain
Paradigm [9]&lt;/li>
&lt;li>Compromised npm Package: event-stream [10]&lt;/li>
&lt;li>Secure at every step: What is software supply chain security and why does it
matter? [11]&lt;/li>
&lt;li>CCleaner Attack Timeline—Here’s How Hackers Infected 2.3 Million PCs [12]&lt;/li>
&lt;li>The Untold Story of NotPetya, the Most Devastating Cyberattack in History
[13]&lt;/li>
&lt;li>Secure open source collaboration: an empirical study of linus’ law [14]&lt;/li>
&lt;li>The State of Open Source Security [15]&lt;/li>
&lt;li>Backstabber’s knife collection: A review of open source software supply chain
attacks [16]&lt;/li>
&lt;li>CII Best Practices Badge Program [17]&lt;/li>
&lt;li>Open Source Security Metrics [18]&lt;/li>
&lt;li>Security Scorecards for Open Source Projects [19]&lt;/li>
&lt;li>Small world with high risks: A study of security threats in the npm ecosystem
[20]&lt;/li>
&lt;/ul>
&lt;h3 id="methodology">Methodology&lt;/h3>
&lt;blockquote>
&lt;p>What methodology did the author&amp;rsquo;s use to validate their contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s identified weak link signals by analyzing potential vulnerabilities
regarding the maintainer and contributor information in a &lt;code>npm&lt;/code> package&amp;rsquo;s
&lt;code>package.json&lt;/code> file. They then validated their weak links by measuring how
frequently they appear in the unique set of the join between the top 10,000 most
popular and the most frequently downloaded packages (with duplicates removed).
This resulted in 14,892 packages to analyze.&lt;/p>
&lt;p>Their proposed weak links were:&lt;/p>
&lt;ul>
&lt;li>Expired Maintainer Email Domain&lt;/li>
&lt;li>Package Installation Script&lt;/li>
&lt;li>Unmaintained Package&lt;/li>
&lt;li>Too Many Maintainers&lt;/li>
&lt;li>Too Many Contributors&lt;/li>
&lt;li>Overloaded Maintainer&lt;/li>
&lt;/ul>
&lt;p>Then they validated the usefulness of their weak links by surveying 470
maintainers about how useful the proposed weak links are as well as other
potential weak links to consider.&lt;/p>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>All weak links proposed by the authors, except for the package installation
script, relied upon an assumption.&lt;/p>
&lt;p>The author&amp;rsquo;s assumed that an accounts with an expired email domain don&amp;rsquo;t have
2FA enabled in their analysis. Additionally, their measurement of expired email
domains is flawed as it relied upon checking if a domain was available for
purchase, and had no check to see if the domain was considered to be a
compromised domain.&lt;/p>
&lt;p>The author&amp;rsquo;s were unable to distinguish between a feature complete package and
an unmaintained package in their analysis.&lt;/p>
&lt;p>The author&amp;rsquo;s arbitrarily assigned a number to represent the max number of
maintainers and contributors to a repository. They also assumed the amount of
work that a maintainer can take on.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>These assumptions don&amp;rsquo;t seem valid to me.&lt;/p>
&lt;p>While being unable to check the 2FA status of an account makes sense, their
methodology for checking email domains was described to flawed and a manual
undertaking even by the author&amp;rsquo;s.&lt;/p>
&lt;p>Additionally, they mentioned that it was difficult to distinguish between a
feature complete and an unmaintained package.&lt;/p>
&lt;p>Finally, they were critiqued by their reviewers (to which I agree with on this
point) that assuming that too many maintainers or contributors is an incorrect
weak link as the nature of open source encourages collaboration and a &amp;ldquo;more the
merrier&amp;rdquo; approach to developing software.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d love to expand off of this work and see if the same issues exist within
pre-trained model supply chains. Additionally, the author&amp;rsquo;s propose further work
into the matter in &lt;em>Section 6: LIMITATIONS&lt;/em> that seems promising and
interesting.&lt;/p>
&lt;h3 id="open-questions">Open Questions&lt;/h3>
&lt;blockquote>
&lt;p>What open questions do I have about the work?&lt;/p>
&lt;/blockquote>
&lt;p>I am curious as to the ethics behind such a study when tooling is built to
analyze potential package vulnerabilities. In other words, is it ethical to
&lt;em>keep&lt;/em> tools to analyze for vulnerabilities, or should they be destroyed after
their intended usage?&lt;/p>
&lt;h3 id="author-feedback">Author Feedback&lt;/h3>
&lt;blockquote>
&lt;p>What feedback would I give to the authors?&lt;/p>
&lt;/blockquote>
&lt;p>Please run the paper through a grammar checking service. Additionally,
understanding the nature and desired outcome of developing open-source software
could have helped when deciding on weak link criteria.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper, &lt;em>What are Weak Links in the npm Supply Chain?&lt;/em> by Nursat Zahan et al.
[1] was published in 2022 in the proceedings of the 44th International
Conference on Software Engineering: Software Engineering in Practice
(ICSE-SEIP). This paper discusses six potential signals that could identify a
package as a weak link within the &lt;code>npm&lt;/code> supply chain. Additionally, the paper
conducted a survey with 470 &lt;code>npm&lt;/code> maintainers about the proposed weak links to
understand their validity and to additionally find potential signals that could
also identify weak links.&lt;/p>
&lt;p>They drew upon industry experience and understanding when determining the six
weak links. Furthermore, these weak links relied upon maintainer and contributor
information derived from the &lt;code>package.json&lt;/code> file of the &lt;code>npm&lt;/code> packages. These
weak links were:&lt;/p>
&lt;ul>
&lt;li>Expired Maintainer Email Domain&lt;/li>
&lt;li>Package Installation Script&lt;/li>
&lt;li>Unmaintained Package&lt;/li>
&lt;li>Too Many Maintainers&lt;/li>
&lt;li>Too Many Contributors&lt;/li>
&lt;li>Overloaded Maintainer&lt;/li>
&lt;/ul>
&lt;p>The author&amp;rsquo;s performed a case study on 14,892 packages to identify the
prevalence of these weak links. They then validated the usefulness of these weak
links by surveying 470 contributors. They found that surveyors agreed with the
first three weak links, but not the remaining three as it went against the ethos
of open source development. They also proposed eight new weak links which were
not validated by the authors:&lt;/p>
&lt;ul>
&lt;li>Ownership Transfer&lt;/li>
&lt;li>Adding New Maintainers&lt;/li>
&lt;li>Maintainer Identity&lt;/li>
&lt;li>Maintainer Two-Factor Authentication&lt;/li>
&lt;li>No Source Code Repository&lt;/li>
&lt;li>&lt;code>npm&lt;/code> Package vs Source Code Repository&lt;/li>
&lt;li>CI/CD Pipeline&lt;/li>
&lt;li>Open Pull Request&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/what-are-weak-links-in-the-npm-supply-chain/</description></item><item><title>A summary of How Developers and Managers Define and Trade Productivity for Quality by Margaret-Anne Storey et al.</title><link>https://nsynovic.dev/summaries/how-developers-and-managers-define-and-trade-productivity-for-quality/</link><pubDate>Thu, 27 Oct 2022 16:03:42 -0500</pubDate><guid>https://nsynovic.dev/summaries/how-developers-and-managers-define-and-trade-productivity-for-quality/</guid><description>&lt;h1 id="a-summary-of-how-developers-and-managers-define-and-trade-productivity-for-quality">A summary of &lt;em>How Developers and Managers Define and Trade Productivity for Quality&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Margaret-Anne Storey et al.; &lt;a href="https://doi.org/10.1145/3528579.3529177">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-how-developers-and-managers-define-and-trade-productivity-for-quality">A summary of &lt;em>How Developers and Managers Define and Trade Productivity for Quality&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#problem">Problem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#methodology">Methodology&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#open-questions">Open Questions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-feedback">Author Feedback&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Read the title, abstract, introduction, section and sub-section headings, and
conclusion&lt;/p>
&lt;/blockquote>
&lt;h3 id="problem">Problem&lt;/h3>
&lt;blockquote>
&lt;p>What is the problem addressed in the paper?&lt;/p>
&lt;/blockquote>
&lt;p>This paper aims to understand the issue of developers and managers having
differing views of productivity, and when to trade the quality of the product
for more productivity. Additionally, this calls into question what is quality,
as well as how does one measure both of these attributes.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this paper as it provides a case study conducted with
Microsoft developers and managers about how they measure and value productivity.
Thereby allowing establishing what a sample of developers define productivity
as, and what a sample of managers define it as well. Additionally, the authors
propose utilize their existing framework SPACE to codify developer and manager
responses. They also propose a new framework, TRUCE, designed to help developers
and managers make decisions about software quality vs productivity trade-offs.
These frameworks are related but provide different lenses into software
development.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is a survey paper of practitioners in industry.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is closely related to industry metric usage survey papers,
productivity and quality papers, and - more broadly - papers that discuss the
usage of and of software metrics in teams.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their contributions is a survey of what developers and managers at Microsoft
consider to be productivity and quality, as well as the TRUCE framework for
identifying when productivity should be comprimised for quality.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;blockquote>
&lt;p>A proper read through of the paper is required to answer this&lt;/p>
&lt;/blockquote>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done into understanding what software quality is, how to measure
productivity, and what is productivity. Also, the authors have previously
described a framework called SPACE (Satisfaction, Performance, Activity,
Collaboration, and Efficiency) which was used to codify the responses from the
survey participants.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the figures are labeled properly, easy to understand, and have clear
captions.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is well written. However, I&amp;rsquo;m not a fan with how the abstract was
structured. I found the topic-description approach didn&amp;rsquo;t engage me as a reader.
But that is more of a personal opinion than an objective fact.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://doi.org/10.1145/3454122.3454124">The SPACE of Developer Productivity: There’s More to It than You Think&lt;/a>
[2]&lt;/li>
&lt;li>&lt;a href="https://doi.org/10.1109/TSE.2018.2842201">Motivation and satisfaction of software engineers&lt;/a>
[3]&lt;/li>
&lt;li>&lt;a href="https://doi.org/10.1007/978-1-4842-4221-6_3">Why We Should Not Measure Productivity&lt;/a>
[4]&lt;/li>
&lt;li>&lt;a href="https://www.microsoft.com/en-us/research/publication/appendix-to-productivity-quality-alignment">Appendix to How Developers and Managers Define and Trade Off Productivity and Quality&lt;/a>
[5]&lt;/li>
&lt;li>&lt;a href="https://doi.org/10.1109/TSE.2019.2944354">Towards a Theory of Software Developer Job Satisfaction and Perceived Productivity&lt;/a>
[6]&lt;/li>
&lt;/ul>
&lt;h3 id="methodology">Methodology&lt;/h3>
&lt;blockquote>
&lt;p>What methodology did the author&amp;rsquo;s use to validate their contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The authors conducted a survey of Microsoft developers and managers on how they
define productivity and quality, as well as the trade offs between productivity
and quality. 167 responses were collected, with 131 responses being from
developers and 34 from managers. Responses were codified using the SPACE
methodology proposed by the authors in a previous work.&lt;/p>
&lt;p>Comparisons were made between how:&lt;/p>
&lt;ul>
&lt;li>Developers define productivity&lt;/li>
&lt;li>Managers define team productivity&lt;/li>
&lt;li>Developers define quality&lt;/li>
&lt;li>Managers define team quality&lt;/li>
&lt;li>How developers &lt;em>think&lt;/em> managers define team productivity&lt;/li>
&lt;li>How managers &lt;em>think&lt;/em> developers define productivity&lt;/li>
&lt;li>Do developers and managers trade quality for productivity?&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>They propose the TRUCE framework for software quality (Timeliness, Robustness,
User Needs, Collaboration Needs, and Evolvable) based on this study alone.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>I don&amp;rsquo;t think that TRUCE can stand on its own just on this work. Additional
surveys and work need to be done to validate the usefulness and how applicable
this framework is outside of the subset of developers and managers at Microsoft
that responded to the survey. The authors do address this in their paper.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d love to perform a literary review of related works and surveys to identify
if the TRUCE framework is applicable. Additionally, I&amp;rsquo;d like to perform a follow
up study of answering and analyzing the question as to what developers &lt;em>think&lt;/em>
managers consider to be quality work and vice versa.&lt;/p>
&lt;h3 id="open-questions">Open Questions&lt;/h3>
&lt;blockquote>
&lt;p>What open questions do I have about the work?&lt;/p>
&lt;/blockquote>
&lt;p>What prevented the authors from asking about what developers and managers
&lt;em>think&lt;/em> the other considers quality work?&lt;/p>
&lt;p>Can any of the SPACE or TRUCE definitions be quantified automatically by
analyzing feature requests?&lt;/p>
&lt;h3 id="author-feedback">Author Feedback&lt;/h3>
&lt;blockquote>
&lt;p>What feedback would I give to the authors?&lt;/p>
&lt;/blockquote>
&lt;p>I appreciate the clear figures, charts, and tables. I don&amp;rsquo;t like the style of
the abstract as it doesn&amp;rsquo;t engage me as a reader. But the finding boxes that
summarize the survey results per subsection were a nice touch and are
appreciated.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>How Developers and Managers Define and Trade Productivity for
Quality&lt;/em> by Margaret-Anne Storey et al. [1] presents the results of a survey
conducted on 131 Microsoft developers and 34 managers about what they consider
to be productive work, quality work, what the other cohort defines each topic,
and if they have ever made explicit trade offs between productivity and quality.
The authors took the responses and codified them using the SPACE framework that
they proposed in an earlier paper [2].&lt;/p>
&lt;p>They found that developers tend to define productive work as activities (number
of tasks completed or iterations; 50%), efficiency and flow (entering a flow
state; 38%), and productivity (delivering on projects; 35%). Managers tend to
define productive work across the team in productivity (67%), efficiency and
flow (45%), and collaboration (working with others to brainstorm ideas/
providing feedback; 33%).&lt;/p>
&lt;p>However, developers &lt;em>think&lt;/em> managers define team productivity in activity (53%),
productivity (37%), and collaboration (19%). Whereas managers &lt;em>think&lt;/em> developers
define productivity in activity (52%), efficiency and flow (42%), and
productivity (24%). Here, both managers and developers &lt;em>think&lt;/em> the other defines
productivity than what is actually true.&lt;/p>
&lt;p>The take away with productivity, is that all participants defined productivity
under the SPACE framework.&lt;/p>
&lt;p>Quality was defined under the proposed TRUCE (Timeliness, Robustness, User
Needs, Collaboration, Evolution) framework. Developers and managers both define
quality similarly as robustness (71%, 88%), evolution (44%, 33%), and user need
(38%, 39%). Managers rank user need higher than evolution, where as developers
disagree with them.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/how-developers-and-managers-define-and-trade-productivity-for-quality/</description></item><item><title>A summary of Robust Real Time-Face Detection by P. Viola and M.J. Jones</title><link>https://nsynovic.dev/summaries/robust-real-time-face-detection/</link><pubDate>Mon, 24 Oct 2022 19:29:57 -0500</pubDate><guid>https://nsynovic.dev/summaries/robust-real-time-face-detection/</guid><description>&lt;h1 id="a-summary-of-robust-real-time-face-detection">A summary of &lt;em>Robust Real-Time Face Detection&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>P. Viola and M.J. Jones;
&lt;a href="https://doi.org/10.1023/B:VISI.0000013087.49260.fb">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-robust-real-time-face-detection">A summary of &lt;em>Robust Real-Time Face Detection&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Robust Real-Time Face Detection&lt;/em> by P. Viola and M.J. Jones [1]
presents a new methodology for efficiently performing face detection. They due
this through the usage of an integral image which is able to reduce the
computational complexity to constant time (O(1)) of analyzing an image as it
doesn&amp;rsquo;t rely on scale invariance and thus an image pyramid. Additional, the
classifier that they build is &amp;ldquo;simple and efficient&amp;rdquo; and allows for the engineer
to specify a large number of features to be analyzed without compromising on
performance as it relies upon the Ada Boost algorithm to select important
features. Furthermore, the authors propose a method for building a cascade of
classifiers which further reduces computation time as each classifier specifies
. Finally, they propose experiments that can be ran on face detection data sets
to conduct supervised learning.&lt;/p>
&lt;p>While this paper does propose many new and innovative ideas, the paper
originates from 2003.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is a research paper focusing on improving the Computer Vision task of face
detection without the reliance of CNNs.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is most closely related to non-CNN face detection papers.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>They create an integral image which is able to reduce the computational
complexity to constant time (O(1)) of analyzing an image as it doesn&amp;rsquo;t rely on
scale invariance and thus an image pyramid. Additionally, the classifier that
they build is &amp;ldquo;simple and efficient&amp;rdquo; and allows for the engineer to specify a
large number of features to be analyzed without compromising on performance as
it relies upon the Ada Boost algorithm to select important features.
Furthermore, the authors propose a method for building a cascade of classifiers
which further reduces computation time as each classifier specifies . Finally,
they propose experiments that can be ran on face detection data sets to conduct
supervised learning.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;blockquote>
&lt;p>A proper read through of the paper&lt;/p>
&lt;/blockquote>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Prior work has been done in creating face detection systems. Prior work has been
done in creating the Ada Boost algorithm that is used to create a cascade of
classifiers. Prior work has been done in identifying methodologies to create
image features.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this paper as it presents a non-CNN methodology for
reliably identifying faces in images. Additionally, the authors also present a
methodology for doing this task efficiently on low end hardware.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>The figures, diagrams, and graphs are well explained and designed.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>Yes, however a bit lengthy. Optimizations could have been made with respect to
reducing the amount of content describing the background to the Ada Boost
algorithm.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>A Decision-Theoretic Generalization of On-Line Learning and an Application to
Boosting [2]&lt;/li>
&lt;/ul>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d like to implement their work on a low powered device and compare it to a
newer CNN model on ML metrics.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Robust Real-Time Face Detection&lt;/em> by P. Viola and M.J. Jones [1]
presents a new methodology for efficiently performing face detection. They due
this through the usage of an integral image which is able to reduce the
computational complexity to constant time (O(1)) of analyzing an image as it
doesn&amp;rsquo;t rely on scale invariance and thus an image pyramid. Additionally, the
classifier that they build is &amp;ldquo;simple and efficient&amp;rdquo; and allows for the engineer
to specify a large number of features to be analyzed without compromising on
performance as it relies upon the Ada Boost algorithm to select important
features. Furthermore, the authors propose a method for building a cascade of
classifiers which further reduces computation time as each classifier specifies
. Finally, they propose experiments that can be ran on face detection data sets
to conduct supervised learning.&lt;/p>
&lt;p>The main &amp;ldquo;wow&amp;rdquo; factor of this work is that it was built on a low powered system.
This same application could be more performant on modern smartphones in
comparison to the system that it was originally tested on.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/robust-real-time-face-detection/</description></item><item><title>A summary of Learning Deep Features for Discriminative Localization by Bolei Zhou et al.</title><link>https://nsynovic.dev/summaries/learning-deep-features-for-discriminative-localization/</link><pubDate>Mon, 24 Oct 2022 14:44:26 -0500</pubDate><guid>https://nsynovic.dev/summaries/learning-deep-features-for-discriminative-localization/</guid><description>&lt;h1 id="a-summary-of-learning-deep-features-for-discriminative-localization">A summary of &lt;em>Learning Deep Features for Discriminative Localization&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Bolei Zhou et al.; &lt;a href="http://arxiv.org/abs/1512.04150">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-learning-deep-features-for-discriminative-localization">A summary of &lt;em>Learning Deep Features for Discriminative Localization&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Learning Deep Features for Discriminative Localization&lt;/em> by Bolei Zhou
et al. [1] describes using the global average pooling layer of CNNs to not
only regularize data, but also to localize objects in an image &lt;strong>even if the
network wasn&amp;rsquo;t trained for object detection&lt;/strong>. The authors propose a method for
object localization that involves a simple modification to the layer to generate
what they call &amp;ldquo;class activation maps&amp;rdquo; (CAMs), which are heat maps of where the
CNN is &amp;ldquo;looking&amp;rdquo; at an image for labeling. The hotter the heat map, the more
focus the CNN is putting on that specific image region.&lt;/p>
&lt;p>The authors go into detail as to how one would accomplish this with a
weakly-supervised object localization method, and its applications towards deep
features for generic localization, fine-grained recognition, and pattern
discovery. They conclude with visualizing class specific units.&lt;/p>
&lt;p>Their technique accomplishes object localization in a single forward pass on
existing CNN models that utilize a global average pooling layer.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is a CNN understanding and technique paper. It discusses a method for
understanding what a CNN is looking at as well as expanding the usage of image
classifiers for object localization.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is related to works involving object localization, image
classification, CNNs, and Deep Learning papers.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s main contribution is a method for modifying the global average
pooling layer in CNNs to perform object localization in a single forward pass.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>There has been work done in utilizing weakly-supervised learning to perform
object localization. However, these works either don&amp;rsquo;t evaluate the object
localization task, or utilize multiple passes to perform the task.&lt;/p>
&lt;p>There has been numerous work that has gone into visualizing what occurs within a
CNN. Additionally, there has been work that has looked at the global &lt;em>max&lt;/em>
pooling layer, however, this work is the first to utilize the global &lt;em>average&lt;/em>
layer.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this paper as it provides a methodology of utilizing
existing CNNs trained on image classification to perform object localization
tasks &amp;ldquo;for free&amp;rdquo;. In other words, this paper presents a methodology for object
localization by reusing existing SOTA CNNs.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the figures and tables are labeled clearly, have detailed captions, and
make sense with respect to the paper.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is well written.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Self-taught object localization with deep networks [2]&lt;/li>
&lt;li>Weakly supervised object localization with multi-fold multiple instance
learning [3]&lt;/li>
&lt;li>Learning and transferring mid-level image representations using convolutional
neural networks [4]&lt;/li>
&lt;li>Is object localization for free? weakly-supervised learning with convolutional
neural networks [5]&lt;/li>
&lt;li>Visualizing and understanding convolutional networks [6]&lt;/li>
&lt;li>Object detectors emerge in deep scene CNNs [7]&lt;/li>
&lt;li>Network in network [8]&lt;/li>
&lt;li>Going deeper with convolutions [9]&lt;/li>
&lt;/ul>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I would love to take this work and apply it to my current research in low
powered computer vision. By utilizing larger networks to localize where in a
static scene the object of interest is most likely to be in (for example, a
static video of a bird sitting on a wire), I can pass in this mapping into a CNN
to specifically be interested in that region of the video/ image. Additionally,
by figuring out where a larger CNN is localizing data, I can then mask out any
cold area of the image prior to analysis by a smaller CNN.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Learning Deep Features for Discriminative Localization&lt;/em> by Bolei Zhou
et al. [1] discusses a weakly supervised method of performing object
localization on existing CNN models. Their method involves replacing the fully
connected layer at the end of a CNN performing image classification, with a
global average pooling layer into a Softmax layer. This is so that the models
original functionality is not cut from the new model. However, the global
average pooling layer is modified so that a heat map can be extracted focusing
on what the CNN is focusing on prior to labeling the image.&lt;/p>
&lt;p>Previous work involved the usage of weakly supervised CNNs, but relied on global
max pooling. Additional work utilized deconvolutional layers to perform a
similar task.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/learning-deep-features-for-discriminative-localization/</description></item><item><title>A summary of How to implement SVMs by John Platt</title><link>https://nsynovic.dev/summaries/how-to-implement-svms/</link><pubDate>Mon, 24 Oct 2022 13:46:36 -0500</pubDate><guid>https://nsynovic.dev/summaries/how-to-implement-svms/</guid><description>&lt;h1 id="a-summary-of-how-to-implement-svms">A summary of &lt;em>How to implement SVMs&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>John Platt; &lt;a href="https://doi.ieeecomputersociety.org/10.1109/5254.708428">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-how-to-implement-svms">A summary of &lt;em>How to implement SVMs&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>How to implement SVMs&lt;/em> by John Platt (as part of the larger &lt;em>Support
vector machine&lt;/em> collection of essays in the July/ August edition of the 1998
IEEE Intelligent Systems magazine) [1] discusses how to implement a Support
Vector Machine (SVM). This essay goes into great detail on implementation
strategies for handling larger data sets, as well as methods for training SVMs.
Topics include understanding the Quadratic Problem (what SVMs aim to solve),
sequential minimal optimization (reaching a global minimal value), and where to
find SVM implementations.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This essay seems to be a tutorial/ workshop paper about SVMs.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>I would expect papers that are about implementing SVMs from scratch would be
related to this essay.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their main contributions are an understanding of how SVMs work as well as how to
implement them efficiently.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has already been done on experimenting optimal SVM algorithms and
minimization functions.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this paper as it provides an understanding of what a SVM is
and how they function.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>The figure and charts have proper labels and captions that explain what they are
representing.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>For the most part, yes. However, the essay expects the reader to be
knowledgeable about SVMs prior to reading the essay. This is shown mostly
through the usage of mathematical notation specific to the problem domain, and
linking to other work to explain it. While this is a short essay for a magazine,
a brief sentence or two about the notation would have been appreciated.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>A Tutorial on Support Vector Machines for Pattern Recognition [2]&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The author assumes that the reader, should they implement their own SVM
algorithm, will be using a commercial numerical analysis package.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>Without understanding the nature of the numerical analysis packages of 1998, I
would assume that this assumption is correct. I base this on that the author
mentions that free numerical analysis packages (not if they were open sourced or
not) run slower than commercial packages and may have errors due to precision
mistakes.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;m not interested in creating my own SVM algorithm. However, having a better
understanding of how SVMs work as well as the different minimization functions
that they implement, would be nice to know.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>How to implement SVMs&lt;/em> by John Platt (as part of the larger &lt;em>Support
vector machine&lt;/em> collection of essays in the July/ August edition of the 1998
IEEE Intelligent Systems magazine) [1] discusses how to implement a Support
Vector Machine (SVM). The author goes into detail about what an SVM is trying to
accomplish (minimize a quadratic problem on a high dimensional matrix), what
techniques exist to solve this problem, as well as available programs to allow
for researchers to utilize SVMs in their work.&lt;/p>
&lt;p>Overall, the essay does a good job of explaining the problem space as well as
implementation details, however, the essay is very much a product of its time.
There is less of a need to develop new SVM algorithms as there are many that are
provided off of the shelf in free and open source numerical analysis packages
[3] [4]. Additionally, the suggestion that readers should purchase a
numerical analysis package to create their own SVM is dated in my opinion, as
again, there are many free options available [5].&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/how-to-implement-svms/</description></item><item><title>A summary of Applying SVMs to Face Detection by Edgar Osuna</title><link>https://nsynovic.dev/summaries/applying-svms-to-face-detection/</link><pubDate>Mon, 24 Oct 2022 09:20:40 -0500</pubDate><guid>https://nsynovic.dev/summaries/applying-svms-to-face-detection/</guid><description>&lt;h1 id="a-summary-of-applying-svms-to-face-detection">A summary of &lt;em>Applying SVMs to Face Detection&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Edgar Isuna; &lt;a href="https://doi.ieeecomputersociety.org/10.1109/5254.708428">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-applying-svms-to-face-detection">A summary of &lt;em>Applying SVMs to Face Detection&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>Applying SVMs to Face Detection&lt;/em> by Edgar Osuna (as part of the
larger &lt;em>Support vector machine&lt;/em> collection of essays in the July/ August edition
of the 1998 IEEE Intelligent Systems magazine) [1] describes the usage of
Support Vector Machines (SVMs) to identify faces in static images and real time
systems. The work goes into detail about previous systems that attempted this
task, as well as a real time system that can classify images at 4 to 5 frames
per second.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is both a small systems essay, as well as a CV task analysis of the
state of the art when using this particular technique.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This essay is most similar to papers that discuss systems that implement face
detection.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s main contributions are a system that utilizes SVMs for real time
facial detection. Additionally, their contributions include a discuss of
previous systems that attempted this task.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Quote from the &lt;em>Previous systems&lt;/em> section of the paper:&lt;/p>
&lt;p>&amp;ldquo;Researchers have approached the face-detection problem with different
techniques in the last few years, including neural networks [2] [3],
detection of face features and use of geometrical constraints [4], density
estimation of the training data [5], labeled graphs [6], and clustering and
distribution-based modeling [7] [8].&amp;rdquo;&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about this essay as it proposes an SVM based solution for both
static image and real time face detection.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>The figures are clear and explained well through their captions. However, Table
2 uses a metric called &amp;ldquo;False Alarms&amp;rdquo; to measure the number of times the system
reported a &amp;ldquo;face&amp;rdquo; that wasn&amp;rsquo;t a face. A more appropriate metric, such as recall,
would have been appropriate in this case.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is well written, however, it can be improved upon. The biggest
complaint that I have is the usage of bullet points to describe tasks/ steps
that were taken to complete a task. Additionally, many bullet points contained
more than one sentence. I find it to be more appropriate for papers to utilize
bullet points for short, unordered lists. Most appropriately used when listing
off different techniques or definitions, which this essay does utilize. Aside
from that, the individual steps are written well and clearly, and seem to be
fairly reproducible.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Detection and localization of faces on digital images [2]&lt;/li>
&lt;li>Human Face Detection in Visual Scenes [3]&lt;/li>
&lt;li>Human face detection in a complex background [4]&lt;/li>
&lt;li>Probabilistic visual learning for object detection [5]&lt;/li>
&lt;li>Determination of face position and pose with a learned representation based on
labeled graphs [6]&lt;/li>
&lt;li>Learning and Example Selection for Object and Pattern Detection [7]&lt;/li>
&lt;li>Example-based learning for view-based human face detection [8]&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The authors trained their system to identify vertically oriented, gray-scale
images of faces for their static image face detector. They make no mention as to
whether this detector is capable of identifying faces in off axis positions, or
if their system is capable enough to orient faces properly.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>Without understanding the availability of data sets at the time, this seems like
a valid assumption to make. However, simple data augmentation (such as rotating
the image) could&amp;rsquo;ve been done to increase the number of training examples of
faces not in the vertical orientation.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>A re-implementation of their work, both on static images and real time image
capture, would be interesting to perform on devices such as cameras, Raspberry
Pis, or other low powered systems. Additionally, comparing the power draw
between an SVM based solution and one that is powered by DL would be interesting
as well.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>Applying SVMS to Face Detection&lt;/em> by Edgar Osuna (as part of the
larger &lt;em>Support vector machine&lt;/em> collection of essays in the July/ August edition
of the 1998 IEEE Intelligent Systems magazine) [1] describes the usage of
Support Vector Machines (SVMs) to identify faces in static images and real time
systems. The author goes into detail about existing systems that were powered by
non-SVM techniques, as well as presenting their own system (for both static
image and real time image capture) for face detection.&lt;/p>
&lt;p>Their static image system only works on gray scale images of vertically aligned
faces. Additionally, they used a small data set to train the SVM. In doing so,
they limit the usage of the static image system to that specific domain, as well
as potentially creating a system that is unable to detect a face in all
potential cases (such as different ethnicity, lighting conditions, face
orientations, etc.).&lt;/p>
&lt;p>Their real time image capture system works on full color images of vertically
aligned faces by using a combination of a skin detector and a &amp;ldquo;primitive&amp;rdquo; motion
detector. This system was capable of recognizing faces at 4 to 5 frames per
second.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/applying-svms-to-face-detection/</description></item><item><title>A summary of Using SVMs For Text Categorization by Susan Dumais et al</title><link>https://nsynovic.dev/summaries/using-svms-for-text-categorization/</link><pubDate>Sun, 23 Oct 2022 16:45:32 -0500</pubDate><guid>https://nsynovic.dev/summaries/using-svms-for-text-categorization/</guid><description>&lt;h1 id="a-summary-of-using-svms-for-text-categorization">A summary of &lt;em>Using SVMs For Text Categorization&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Susan Dumais et al.;
&lt;a href="https://doi.ieeecomputersociety.org/10.1109/5254.708428">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-using-svms-for-text-categorization">A summary of &lt;em>Using SVMs For Text Categorization&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>Using SVMs For Text Categorization&lt;/em> by Susan Dumais et al. (as part
of the larger &lt;em>Support vector machine&lt;/em> collection of essays in the July/ August
edition of the 1998 IEEE Intelligent Systems magazine) [1] provides examples
of when using a Support Vector Machine (SVM) is beneficial with respect to text
classification. They discuss text classification, text representation and
feature selection, and an example use case on the Reuters collection. They
support the position that using SVMs for text classification (or really any
algorithm so long as it isn&amp;rsquo;t run by a human) is beneficial for this task.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This essay is more argumentative and position oriented.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This essay would most likely be classified alongside similar works that
evaluated the usefulness of SVMs with respect to human tasks.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their contributions is an analysis of SVMs for text classification.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done to understand what SVMs are, as well as use cases for SVMs.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Because it provides a case study of using SVMs on the Reuters collection with
respect to text classification.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the graphs and charts are clear to understand and have properly labeled
axis.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>This essay is clearly written.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Introduction to Modern Information Retrieval [2]&lt;/li>
&lt;li>Fast Training of SVMs Using Sequential Minimal Optimization [3]&lt;/li>
&lt;/ul>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I would like to implement their study using the five different learning
algorithms they utilized to validate their results. The algorithms in question
are: Findsim, Naive Bayes, BayesNets, Trees, and LinearSVM.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>Using SVMs For Text Categorization&lt;/em> by Susan Dumais et al. (as part
of the larger &lt;em>Support vector machine&lt;/em> collection of essays in the July/ August
edition of the 1998 IEEE Intelligent Systems magazine) [1] presents the usage
of SVMs for text categorization on the Reuters collection in comparison to other
classification algorithms. They found that SVMs perform best on this
classification task.&lt;/p>
&lt;p>The greater reason for this essay is to encourage engineers to use learning
algorithms for human intensive tasks - such as text classification.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/using-svms-for-text-categorization/</description></item><item><title>A summary of SVMs - A Practical Consequence of Learning Theory by Bernhard Scholkopf</title><link>https://nsynovic.dev/summaries/svms-a-practical-consequence-of-learning-theory/</link><pubDate>Sun, 23 Oct 2022 10:02:41 -0500</pubDate><guid>https://nsynovic.dev/summaries/svms-a-practical-consequence-of-learning-theory/</guid><description>&lt;h1 id="a-summary-of-svms-a-practical-consequence-of-learning-theory">A summary of &lt;em>SVMs: A Practical Consequence of Learning Theory&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Bernhard Scholkopf;
&lt;a href="https://doi.ieeecomputersociety.org/10.1109/5254.708428">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-svms-a-practical-consequence-of-learning-theory">A summary of &lt;em>SVMs: A Practical Consequence of Learning Theory&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>SVMs - a practical consequence of learning theory&lt;/em> by Bernhard
Scholkopf (as part of the larger &lt;em>Support vector machine&lt;/em> collection of essays
in the July/ August edition of the 1998 IEEE Intelligent Systems magazine) [1]
discusses the underlying theory that powers Support Vector Machine (SVM)
algorithms and argues that these algorithms are useful and performant. His essay
contains sections on &lt;em>Learning pattern recognition from examples&lt;/em>,
&lt;em>Hyperplanes&lt;/em>, &lt;em>Feature spaces and kernels&lt;/em>, &lt;em>SVMs&lt;/em>, and &lt;em>Current developments
and open issues&lt;/em> which indicates an essay that will holistically look at SVMs,
rather than a particular facet of them.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is best classified as an informative essay on the benefits of SVMs
from a theoretical and practical view.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is most related to other papers within the magazine&amp;rsquo;s collection, as
well as work that goes into the theory behind SVMs.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>A brief description of the theory that powers SVMs, as well as identifying where
SVMs are practical.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Work has been done to develop and implement the SVM algorithm.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Because it provides a concise description of the theory that powers SVMs, and
practical usages of SVMs.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>The paper doesn&amp;rsquo;t provide and graphs or charts. However, the figures and
diagrams that are presented are clearly explained in the descriptions, are well
made, and are easy to comprehend.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>Sort of? The theory components of the essay are written distinctly differently
than the introduction and concluding sections of the paper. This could be due to
the discussion of mathematical prose; but due to this, the essay has two
different voices.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>The Nature of Statistical Learning Theory [2]&lt;/li>
&lt;/ul>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;d like to explore the usage of SVMs for face or object detection and compare
it against the usage of DL techniques on both traditional and low-powered
metrics.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The essay &lt;em>SVMs: A Practical Consequence of Learning Theory&lt;/em> by Bernhard
Scholkopf (as part of the larger &lt;em>Support vector machine&lt;/em> collection of essays
in the July/ August edition of the 1998 IEEE Intelligent Systems magazine) [1]
discuss both the mathematical theory and current practice of using SVMs. SVMs
are useful in a research aspect as their functionality can be mathematically
explained. SVMs are a linear classifier that operate in multi-dimensional space
through the usage of a hyper plane. Hyper planes are chosen by finding support
vectors, which are instances of a class that are closest to one another. The
hyper plane then splits these two instances into two separable sides. To assist
in this calculation, a kernel algorithm is applied to map one multi-dimensional
space to another for easier computation.&lt;/p>
&lt;p>Overall, this paper provides a good understanding of the theory behind SVMs. It
also alludes to additional usages of SVMs and their current problems, but it is
not focused on discussing or resolving them.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/svms-a-practical-consequence-of-learning-theory/</description></item><item><title>A summary of Runnemede: An Architecture for Ubiquitous High-Performance Computing by Nicholas P. Carter et al.</title><link>https://nsynovic.dev/summaries/runnemede-an-architecture-for-ubiquitous-high-performance-computing/</link><pubDate>Fri, 30 Sep 2022 09:07:41 -0500</pubDate><guid>https://nsynovic.dev/summaries/runnemede-an-architecture-for-ubiquitous-high-performance-computing/</guid><description>&lt;h1 id="a-summary-of-runnemede-an-architecture-for-ubiquitous-high-performance-computing">A summary of &lt;em>Runnemede: An Architecture for Ubiquitous High-Performance Computing&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Nicholas P. Carter et al;
&lt;a href="https://doi.org/10.1109/HPCA.2013.6522319">https://doi.org/10.1109/HPCA.2013.6522319&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-runnemede-an-architecture-for-ubiquitous-high-performance-computing">A summary of &lt;em>Runnemede: An Architecture for Ubiquitous High-Performance Computing&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Runnemede: An Architecture for Ubiquitous High-Performance Computing&lt;/em>
by Nicholas P. Carter et al. [1] describes the Runnemede high performance
computing architecture targeting extreme-scale systems. This architecture was
developed for the DARPA&amp;rsquo;s Ubiquitous High-Performance Computing program. The
authors describe multiple facets of the architecture including the networking,
hardware and software design, the energy efficiencies of the architecture. They
also evaluate the performance of the architecture as well. Their many
contributions are a theoretical architecture that is well optimized for energy
efficiency on extra-scale computers.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is a theoretical paper describing an architecture for HPC systems.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>Similar works would involve HPC architecture descriptions as well as low powered
computing architectures as well.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their contributions are a theoretical design and analysis of a HPC architecture
focused on energy efficiency.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Runnemede is a one of four architectures under the DARPA UHPC program.
Additionally, work has been done before to build both low powered cluster
computers, and HPC.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>The justification for this work is that there exists a theory that larger and
larger HPC computers will require more and more power, without fully utilizing
the entire device array. Additionally, a test chip was designed, but never
produced, called &amp;ldquo;Sunshine&amp;rdquo;. By designing this chip, the authors were able to
theoretically test the ideas presented in the paper as well as develop new ones
for the architecture.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the figures and tables are clear and easy to understand.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is well written and clear to understand.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>[2]&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The author&amp;rsquo;s assumed that, &amp;ldquo;&amp;hellip; The power consumed by logic is expected to scale
well as feature sizes shrink, but not as well as transistor density, leading to
the design of &lt;em>over provisioned, energy-limited&lt;/em> systems that contain more
hardware than they can operate simultaneously&amp;rdquo;. In other words, systems will
have more and more &lt;em>power hungry&lt;/em> hardware that cannot be utilized in its
entirety. Additionally, they assume that the current trend with DRAM will cause
power consumption to decrement over time, but not fast enough.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>As the year is 2022, the current next generation hardware from NVIDIA, Intel,
and AMD has been announced, all of which require immense power draw to operate.
Additionally, DDR5 DRAM exists and consumes less power than the previous DDR4
DRAM. Therefore, I agree with the assumptions of the authors.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Runnemede: An Architecture for Ubiquitous High-Performance Computing&lt;/em>
by Nicholas P. Carter et al. [1] describes the Runnemede high performance
computing architecture targeting extreme-scale systems. This architecture was
developed for the DARPA&amp;rsquo;s Ubiquitous High-Performance Computing program to
address over provisioned, energy limited HPC architecture designs. The authors
proposed a theoretical architecture design, and justify it via bench marking
that they performed with simulations. Their work assumes (correctly in my
opinion) that systems will continue to require more power to operate in order to
achieve better performance.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/runnemede-an-architecture-for-ubiquitous-high-performance-computing/</description></item><item><title>A summary of ImageNet Classification with Deep Convolutional Neural Networks by Krizhevsky et al.</title><link>https://nsynovic.dev/summaries/imagenet-classification-with-deep-convolutional-neural-networks/</link><pubDate>Thu, 29 Sep 2022 14:33:01 -0500</pubDate><guid>https://nsynovic.dev/summaries/imagenet-classification-with-deep-convolutional-neural-networks/</guid><description>&lt;h1 id="a-summary-of-imagenet-classification-with-deep-convolutional-neural-networks">A summary of &lt;em>ImageNet Classification with Deep Convolutional Neural Networks&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Krizhevsky et al.;
&lt;a href="https://doi.org/10.1145/3065386">https://doi.org/10.1145/3065386&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-imagenet-classification-with-deep-convolutional-neural-networks">A summary of &lt;em>ImageNet Classification with Deep Convolutional Neural Networks&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#discussion-of-the-proofs">Discussion of the Proofs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>ImageNet Classification with Deep Convolutional Neural Networks&lt;/em> by
Krizhevsky et al. discusses the AlexNet model and its architecture as well as
its SOTA achievements in the 2012 ImageNet Challenge. The difference between
AlexNet and other contestants was that the model relies on GPU training to train
the convolutional neural network model. By utilizing the GPU, training time can
be accelerated significantly more than what was previously possible. Their major
contributions is that a large, deep convolutional neural network is capable of
achieving record-breaking results via supervised learning. They did not utilize
unsupervised pre-training, but the authors suspect that it would improve the
accuracy of the model.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is a computer vision model evaluation and architecture paper.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is similar to others that have published about SOTA results from the
ImageNet Challenge.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their main contributions were that training on GPUs allows for accelerated
training, that large and deep convolutional neural networks are effective at
classifying images, and that removing layers does decrease the performance of
models. Therefore, a larger, deeper model is applicable. It should be noted that
AlexNet was the largest model ever at the time of publication.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Previous work on designing convolutional neural networks and architectures.
However, they were bounded by not being particularly deep.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Because it is one of the key papers that demonstrates that large, deep,
convolutional neural networks are effective for image classification. As well as
providing evidence that training on GPUs is not only effective but recommended
for optimal performance. Additionally it provides empirical evidence that
removing a layer from a convolutional neural network is detrimental to the
performance of the model. In other words, the more layers you add, the more
potential there is for improvement.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>Nearly all of the figures are designed well, with the exception of Figure 2.
Figure 2 is the model architecture of AlexNet. This figure suffers from
information density and a three dimensional design which makes it hard to
determine what is going on and in what dimension are images being manipulated.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>They assume that it is because of the larger compute devices and data sets that
make these deep convolutional neural networks possible.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>While true, &lt;a href="going-deeper-with-convolutions.md">Szegedy et al.&lt;/a> designed their
own architecture using unique algorithms not prevalent in existing convolutional
neural networks.&lt;/p>
&lt;h3 id="discussion-of-the-proofs">Discussion of the Proofs&lt;/h3>
&lt;p>Their training involved both dropout and data augmentation.&lt;/p>
&lt;p>Dropout involves not using the outputs of neurons whose activation is less than
0.5.&lt;/p>
&lt;p>Data augmentation involves manipulating the input images such that 5 244 x 244
images are derived from one 256 x 256 image (e.g. the four corners and one
centered). Additionally, PCA was done on the RGB channels of all of the images
in the ImageNet 2010 and 2012 data sets. These eigenvectors were then added to
each of the images respective color channels.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>A reimplementation of the work would be interesting, with particular respect to
bench marking training time, as the authors were limited by their GPU compute
units&amp;rsquo; performance.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>&lt;em>Taken from &lt;a href="#first-pass">First Pass&lt;/a>&lt;/em>&lt;/p>
&lt;p>The paper &lt;em>ImageNet Classification with Deep Convolutional Neural Networks&lt;/em> by
Krizhevsky et al. [1] discusses the AlexNet model and its architecture as well
as its SOTA achievements in the 2012 ImageNet Challenge. The difference between
AlexNet and other contestants was that the model relies on GPU training to train
the convolutional neural network model as well as being a deep convolutional
neural network.&lt;/p>
&lt;p>By utilizing the GPU, training time can be accelerated significantly more than
what was previously possible. The benefits of being a deep convolutional neural
network is that the classification of images builds off of the features found in
the previous images. The result of this is that their top 1% and top 5% error
were the lowest ever in the competition.&lt;/p>
&lt;p>They trained their model by utilizing both dropout, where neurons that activated
with a value less than 0.5 are not inputted into the next layer, and by
augmenting the Imagenet 2010 and 2012 data sets to increase the amount of data
that they can throw at the model.&lt;/p>
&lt;p>Their work is important as it kicked off the usage of both deep convolutional
neural networks and the usage of GPUs to reduce training time.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/imagenet-classification-with-deep-convolutional-neural-networks/</description></item><item><title>A summary of Very Deep Convolutional Networks for Large-Scale Image Recognition by Karen Simonyan and Andrew Zisserman</title><link>https://nsynovic.dev/summaries/very-deep-convolutional-networks-for-large-scale-image-recognition/</link><pubDate>Wed, 28 Sep 2022 22:40:46 -0500</pubDate><guid>https://nsynovic.dev/summaries/very-deep-convolutional-networks-for-large-scale-image-recognition/</guid><description>&lt;h1 id="a-summary-of-very-deep-convolutional-networks-for-large-scale-image-recognition-by-karen-simonyan-and-andrew-zisserman">A summary of &lt;em>Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/em> by Karen Simonyan and Andrew Zisserman&lt;/h1>
&lt;blockquote>
&lt;p>Karen Simonyan and Andrew Zisserman;
&lt;a href="https://doi.org/10.48550/arXiv.1409.1556">https://doi.org/10.48550/arXiv.1409.1556&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-very-deep-convolutional-networks-for-large-scale-image-recognition-by-karen-simonyan-and-andrew-zisserman">A summary of &lt;em>Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/em> by Karen Simonyan and Andrew Zisserman&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#background-work">Background Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Very Deep Convolutional Networks for Large Scale Image Recognition&lt;/em>
by Karen Simonyan and Andrew Zissernman discusses the SOTA performance of their
model in the 2014 ImageNet Challenge on localization and classification tasks.
They discuss that be extending the depth of convolutional neural networks to 16
up to 19 layers, with a 3x3 filter size, SOTA performance is possible without
redeveloping the architecture of existing convolutional neural networks. This is
in contrast to &lt;a href="going-deeper-with-convolutions.md">Szegedy&amp;rsquo;s work&lt;/a> who proposes
the Inception architecture for classification and object detection; with which
the reference implementation also came first in the 2014 ImageNet Challenge in
its respective tasks. Simoyan et al. discuss the architecture and training that
went into their model (VGG) and how to architect future models to perform as
well or better.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is both a computer vision model evaluation and architecture paper.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is most closely related to others who publish work regarding SOTA
performance on CV architecture and models.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Their main contributions is an exploration of depth in traditional convolutional
neural networks to achieve SOTA performance.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="background-work">Background Work&lt;/h3>
&lt;blockquote>
&lt;p>What has been done prior to this paper?&lt;/p>
&lt;/blockquote>
&lt;p>Prior work has gone into optimizing the width and initial convolutions of
convolutional neural networks.&lt;/p>
&lt;p>&lt;a href="going-deeper-with-convolutions.md">Szegedy et al.&lt;/a> proposed a new architecture
(Inception) that achieved SOTA performance in the 2014 ImageNet Challenge. Else,
Krizhevsky et al. [2] and others have proposed improvements to the
convolutional neural network architecture.&lt;/p>
&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;blockquote>
&lt;p>Why should we care about this paper?&lt;/p>
&lt;/blockquote>
&lt;p>We should care about the authors work as increasing the depth of a neural
network by their proposed architecture allows for easy expansion of existing
convolutional neural networks without redesigning the libraries used to create
them.&lt;/p>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>The tables that are presented are easy to read, but can be improved upon. Often,
multiple rows will correspond with a single model configuration. This is fine,
however, it is difficult to make out what configuration each row corresponds to.
Additionally, the tables make comparing error percentages easy across model
configurations.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is well written and can be understood.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Classical convolutional neural network architecture - [3]&lt;/li>
&lt;li>GoogLeNet - [2]&lt;/li>
&lt;li>Clarifai&lt;/li>
&lt;li>ImageNet classification with deep convolutional neural net- works [4]&lt;/li>
&lt;li>Isotropically-rescaled training image&lt;/li>
&lt;li>ImageNet 2013 submissions - [5], [6] Localization and Detection using
Convolutional Networks&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>The authors assume that the performance improvements that convolutional neural
networks are achieving are based off of larger data sets and better compute
optimization.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>I agree with their assumption. However, [2] created a SOTA model utilizing a
new architecture, rather than improving upon an existing one.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>I would love to try and optimize the input layer of convolutional neural
networks by having a computation that not only looks at the color space, but
also the opacity of an image. This would allow for images to have their
background removed for the purposes of classification by making the background
less opaque than the foreground.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Very Deep Convolutional Networks for Large Scale Image Recognition&lt;/em>
by Karen Simonyan and Andrew Zissernman discusses the SOTA performance of their
model in the 2014 ImageNet Challenge on localization and classification tasks.
They discuss that be extending the depth of convolutional neural networks to 16
up to 19 layers, with a 3x3 filter size, SOTA performance is possible without
redeveloping the architecture of existing convolutional neural networks. Their
work builds of previous efforts of improving convolutional neural network
performance by optimizing the filter size and initial layer, but contrasts
contemporaries [2] by not developing a new architecture. Their work has
importance as it shows that the existing convolutional neural network
architecture is capable of SOTA performance by increasing the depth of the
model. They justify this by trying six different model configurations, and
finding that models with 16 to 19 layers performed best on the 2014 ImageNet
Challenge classification and localization challenges.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/very-deep-convolutional-networks-for-large-scale-image-recognition/</description></item><item><title>A summary of Going deeper with convolutions by Christian Szegedy et al.</title><link>https://nsynovic.dev/summaries/going-deeper-with-convolutions/</link><pubDate>Wed, 28 Sep 2022 20:07:40 -0500</pubDate><guid>https://nsynovic.dev/summaries/going-deeper-with-convolutions/</guid><description>&lt;h1 id="a-summary-of-going-deeper-with-convolutions">A summary of &lt;em>Going deeper with convolutions&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Christian Szegedy et al.;
&lt;a href="https://doi.org/10.48550/arXiv.1409.4842">https://doi.org/10.48550/arXiv.1409.4842&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-going-deeper-with-convolutions">A summary of &lt;em>Going deeper with convolutions&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Going deeper with convolutions&lt;/em> by Christian Szegedy et al. [1]
describes a 2014 state of the art computer vision model (on the ImageNet
Large-Scale Visual Recognition Challenge) called GoogLeNet architect ed based on
Hebbian principles (i.e. neurons that fire together, are wired together)and a
constant computational budget. Their approach relies on creative algorithms and
neuroscience principles and aims to be a more power efficient model for mobile
devices by limiting the computations during inference. Additionally, their model
is deep but not wide and is considered &amp;ldquo;sparse&amp;rdquo; by the authors. In other words,
there are as few nodes as possible within the neural network.&lt;/p>
&lt;p>Szegedy et al.&amp;rsquo;s contributions are a state of the art computer vision model that
provides experimental evidence that, &amp;ldquo;&amp;hellip; Approximating the expected optimal
sparse structure by readily available dense building blocks is a viable method
for improving neural networks for computer vision&amp;rdquo;. This means that this model
proves that dense neural networks for computer vision are not necessary in the
author&amp;rsquo;s viewpoint.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This is a computer vision paper describing both a machine learning architecture
and reference model.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is related to other computer vision papers that achieve state of the
art performance values based on the ImageNet Large-Scale Visual Recognition
Challenge.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>Szegedy et al.&amp;rsquo;s contributions are:&lt;/p>
&lt;ul>
&lt;li>A computer vision model architecture (Inception) that is both sparse and aims
to be computationally efficient on mobile (non-server) devices,&lt;/li>
&lt;li>A reference model of the aforementioned computer vision model architecture&lt;/li>
&lt;li>A comparison of previous state of the art work to justify their claims that
sparser networks are the future of computer vision models.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>All of the tables have proper column labels. However, Table 1 does not provide
default values for blank cells. This is most likely due to the layer type not
performing a specific operation (as described in the column label). Regardless,
the remaining tables look good.&lt;/p>
&lt;p>Additionally, Figure 3 is very clear to read, if a little dense. However, as it
describes all of the layers of GoogLeNet and how they are connected, I find the
size to be appropriate.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>The paper is fairly well written. The only complaints that I have are minor
grammatical mistakes that the author&amp;rsquo;s left in (by accident I assume).
Additionally, that the authors didn&amp;rsquo;t optimize their tables and figures to
better fit on the pages. As tables and figures are stacked on top of one
another, it would be possible to reclaim paper space by rearranging multiple
tables and figures to be next to one another, with the exception of Figure 3 due
to the sheer size of it.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>Contrast Normalization&lt;/li>
&lt;li>Max Pooling&lt;/li>
&lt;li>Average Pooling&lt;/li>
&lt;li>Softmax Activation&lt;/li>
&lt;li>Dropout - [2]&lt;/li>
&lt;li>Localization Task - [3]&lt;/li>
&lt;li>Gabor Filters - [4]&lt;/li>
&lt;li>Network in Network - [5]&lt;/li>
&lt;li>Rectified Linear Activation - [6]&lt;/li>
&lt;li>Regions with Convolutional Neural Networks - [7]&lt;/li>
&lt;li>Multi-Box Prediction - [8]&lt;/li>
&lt;li>Arora proof - [9]&lt;/li>
&lt;li>LeNet 5 - [10]&lt;/li>
&lt;li>Fisher vectors&lt;/li>
&lt;li>Polyak Averaging - [11]&lt;/li>
&lt;li>Jaccard index&lt;/li>
&lt;li>Selective Search - [12]&lt;/li>
&lt;li>Photometric Distortions - [13]&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>One assumption that the authors make is that over fitting is more prone to occur
in large models. Additionally, over fitting can occur when there is not enough
labeled examples in a data set when a large model is training. Furthermore,
increasing the size of a model increases the number of computations that must be
done between layers (e.g. chaining two convolutional layers results in
computation cost quadratic ally increasing) Their solutions relies on moving
from fully connected to sparsely connected architectures including within
convolutional layers. Also, their model architecture is based on the idea that
computers are inefficient when, &amp;ldquo;&amp;hellip; Computing numerical calculations on
non-uniform sparse data structures&amp;rdquo;.&lt;/p>
&lt;p>They assume that 1x1, 3x3, and 5x5 filters are the proper filters to use, but
did not test other size of filters. They also assume that using, &amp;ldquo;Inception
modules&amp;rdquo; is only useful at higher levels, whereas the initial levels are
standard convolutional levels. However, this was not tested either and was due
to, &amp;ldquo;infrastructural inefficiencies&amp;rdquo; in the implementation.&lt;/p>
&lt;p>Finally, that the model that achieved state of the art performance was the best
model. The authors had been training and testing other models for months prior,
however, it is unclear what the testing methodology was and why a particular
model was chosen to compete in the ImageNet competition.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>The first paragraph of assumptions seems reasonable and correct. However, the
remaining two paragraphs seem unreasonable. This is due to the lack of testing
that the author&amp;rsquo;s put in when optimizing their model with respect to the filter
sizes and choosing models. Furthermore, if testing did occur to address these
issues, it is not addressed in this paper, thus leaving the reader to wonder why
testing wasn&amp;rsquo;t performed.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;p>Based off of Section 3 (Motivation and High Level Considerations), one promising
area of study would be to perform a network architecture search utilizing the
principles and reasoning of their approach to other machine learning and
computer vision domains.&lt;/p>
&lt;p>An enhancement to their work is possible by analyzing what filter sizes most
optimal improve performance. Currently the author&amp;rsquo;s are restricting GoogLeNet to
1x1, 3x3, and 5x5 filter sizes, but this was due to convenience and no data was
given to support this.&lt;/p>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>Going deeper with convolutions&lt;/em> by Szegedy et al. [1] introduces a
computer vision model architecture called Inception and a reference model called
GoogLeNet.&lt;/p>
&lt;p>Inception is a model architecture that is both sparse and (attempts to be)
computationally efficient during inferencing with only 1.5 billion multiply-add
operations allowed. Inception models are composed of multiple Inception modules
that are stacked on top of each other. Each Inception module takes in data from
the previous layer and passes it into small convolutional filters (i.e. 1x1
typically). There are three of these small filters that are wired to the input
of the Inception module, with one of them connected directly to the output. The
outputs of two of these filters are then passed into larger filters (i.e. 5x5)
to which it is then passed into a DepthConcat function. Additionally, a 3x3
filter is wired to the input of the module and the output of which goes into a
1x1 filter to be passed into the DepthConcat function as well. From there, it is
passed into another Inception module and the process repeats.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> Depth when referring to two dimensional images refers to the color
channel of the image. As images typically have three color channels (i.e. red,
green, blue), an image would have a depth of 3.&lt;/p>
&lt;p>&lt;em>Example:&lt;/em> A 200 pixel by 200 pixel full color spectrum image would be
represented as 200x200x3.&lt;/p>
&lt;p>It is possible for Inception modules to have an additional connection to the
input of the module to perform average pooling for Softmax activation.&lt;/p>
&lt;p>GoogLeNet achieved SOTA performance in the ImageNet Large-Scale Visual
Recognition Challenge image classification task by having a top-5 error of 6.67%
on both the validation and testing data. This is an improvement of 56.5% in
comparison to 2012&amp;rsquo;s SOTA performer (SuperVision) and 2013&amp;rsquo;s SOTA performer
(Clarifai). Additionally, they achieved SOTA performance for the ImageNet
Large-Scale Visual Recognition Challenge detection task with a mean average
precision of 43.9% utilizing an ensemble inference approach. This model was
architected using the Inception architecture with 22 layers. However, not every
layer was an Inception module; the first few layers were standard convolutional
layers.&lt;/p>
&lt;p>The author&amp;rsquo;s contributions were as follows;&lt;/p>
&lt;ol>
&lt;li>The Inception computer vision architecture,&lt;/li>
&lt;li>The GoogLeNet SOTA computer vision model for classification and object
detection.&lt;/li>
&lt;/ol>
&lt;p>My opinion on this paper is that while it is well written, the author&amp;rsquo;s make
numerous assumptions about the optimal performance of their model&amp;rsquo;s
architecture. They don&amp;rsquo;t test optimal sizes for filters as well as resolving
bugs such as the usage of standard convolutional layers early in the model. Both
of which can be solved by performing a neural architecture search.&lt;/p>
&lt;p>Future work for this paper would involve optimizing the model architecture via a
neural architecture search. As well as evaluating the performance of the model
by both increasing and decreasing the depth of the model.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/going-deeper-with-convolutions/</description></item><item><title>A summary of How to Read a Paper by S. Keshav</title><link>https://nsynovic.dev/summaries/how-to-read-a-paper/</link><pubDate>Wed, 28 Sep 2022 15:11:09 -0500</pubDate><guid>https://nsynovic.dev/summaries/how-to-read-a-paper/</guid><description>&lt;h1 id="a-summary-of-how-to-read-a-paper">A summary of &lt;em>How to Read a Paper&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>S. Keshav;
&lt;a href="https://doi.org/10.1145/1273445.1273458">https://doi.org/10.1145/1273445.1273458&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-how-to-read-a-paper">A summary of &lt;em>How to Read a Paper&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-pass">First Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#category">Category&lt;/a>&lt;/li>
&lt;li>&lt;a href="#context">Context&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#correctness">Correctness&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#contributions">Contributions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clarity">Clarity&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#second-pass">Second Pass&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#relevant-work">Relevant Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#author-assumptions">Author Assumptions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#discussion-of-the-proofs">Discussion of the Proofs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#how-would-i-present-the-ideas">How Would I Present the Idea(s)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#future-directions">Future Directions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summarization-technique">Summarization Technique&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="first-pass">First Pass&lt;/h2>
&lt;blockquote>
&lt;p>Discussion about the title, abstract, introduction, section and sub-section
headings, and conclusion&lt;/p>
&lt;/blockquote>
&lt;p>The paper, &lt;em>How to Read a Paper&lt;/em> by S. Keshav is a tutorial for graduate
students on how to read an academic paper. They propose a &amp;ldquo;three-pass&amp;rdquo; approach
that aims to reduce the frustration that graduate students face when reading
papers. Additionally, they discuss how to perform a literature survey of a new
field, their experience with this methodology, and write that this document is
meant to exist as a living work, with adjustments to be made as seen fit by the
author.&lt;/p>
&lt;h3 id="category">Category&lt;/h3>
&lt;blockquote>
&lt;p>What type of paper is this work?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is definitely a more causal piece of academic work that aims at
easing students into the reading papers. I would classify this paper as &amp;ldquo;meta&amp;rdquo;,
educational, or as a formal letter to students. The later classification is due
to the lack of surveys or qualitative/ quantitative data from others that have
applied this or similar methods to reading papers.&lt;/p>
&lt;h3 id="context">Context&lt;/h3>
&lt;blockquote>
&lt;p>What other &lt;em>types&lt;/em> of papers is the work related to?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is most closely related to papers that discuss the writing of
academic works and the review process of academic works.&lt;/p>
&lt;h4 id="correctness">Correctness&lt;/h4>
&lt;blockquote>
&lt;p>Do the assumptions seem valid?&lt;/p>
&lt;/blockquote>
&lt;p>The assumptions in the abstract and introduction seem reasonable. However,
assuming that only graduate students are the only ones that struggle with
reading academic works is unrepresentative of &lt;em>my particular experience&lt;/em>.
Undergraduate students as well as professionals in industry also struggle with
reading these works as well.&lt;/p>
&lt;h3 id="contributions">Contributions&lt;/h3>
&lt;blockquote>
&lt;p>What are the author&amp;rsquo;s main contributions?&lt;/p>
&lt;/blockquote>
&lt;p>S. Keshav&amp;rsquo;s contributions is a three-stage process for reading papers and a
framework for performing literature reviews of a new field.&lt;/p>
&lt;h3 id="clarity">Clarity&lt;/h3>
&lt;blockquote>
&lt;p>Is the paper well written?&lt;/p>
&lt;/blockquote>
&lt;p>This paper is well written and is easy to comprehend. I would strongly recommend
this paper to be read by everyone regardless of academic status.&lt;/p>
&lt;hr>
&lt;h2 id="second-pass">Second Pass&lt;/h2>
&lt;h3 id="figures-diagrams-illustrations-and-graphs">Figures, Diagrams, Illustrations, and Graphs&lt;/h3>
&lt;blockquote>
&lt;p>Are the axes properly labeled? Are results shown with error bars, so that
conclusions are statistically significant?&lt;/p>
&lt;/blockquote>
&lt;p>There are no illustrations to discuss in this paper.&lt;/p>
&lt;h3 id="relevant-work">Relevant Work&lt;/h3>
&lt;blockquote>
&lt;p>Mark relevant work for review&lt;/p>
&lt;/blockquote>
&lt;p>The following relevant work can be found in the &lt;a href="#citations">Citations&lt;/a> section
of this article.&lt;/p>
&lt;ul>
&lt;li>[1], [2], [3], and [4]&lt;/li>
&lt;/ul>
&lt;h3 id="author-assumptions">Author Assumptions&lt;/h3>
&lt;blockquote>
&lt;p>What assumptions does the author(s) make? Are they justified assumptions?&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;m nit-picking here, but the S. Keshav focuses solely on graduate students as
the demographic that has trouble reading academic papers. Now while graduate
students do typically read more papers than undergraduates, it is not unheard of
for academic readings to be given to undergraduate students as homework
assignments or for them to read them on their own. Additionally, professionals
in industry also struggle with this task as well. A more inclusive audience
would have been appreciated, but would not have improved the content or quality
of this paper.&lt;/p>
&lt;h3 id="discussion-of-the-proofs">Discussion of the Proofs&lt;/h3>
&lt;p>The only proof of the &amp;ldquo;three-pass&amp;rdquo; method that was discussed was the experience
of the author. An awfully biased proof, however, I do appreciate at least some
quantifiable data for this method.&lt;/p>
&lt;h3 id="how-would-i-present-the-ideas">How Would I Present the Idea(s)&lt;/h3>
&lt;p>I think the author presented these ideas exceptionally well and clearly, and
cannot think of any additional presentation method aside from the critiques of
the assumptions mentioned in &lt;a href="#author-assumptions">Author Assumptions&lt;/a>.&lt;/p>
&lt;h3 id="future-directions">Future Directions&lt;/h3>
&lt;blockquote>
&lt;p>My own proposed future directions for the work&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>A survey of graduate students on their methodology for reading papers&lt;/li>
&lt;li>A survey of industry professionals on their methodology for reading papers&lt;/li>
&lt;li>An artifact that allows for a user to step through a set series of steps to
properly understand a document.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>A summary of the paper&lt;/p>
&lt;/blockquote>
&lt;p>The paper &lt;em>How to Read a Paper&lt;/em> by S. Keshav is a &amp;ldquo;meta&amp;rdquo; or educational paper
about how to read an academic work. Their main contributions are a three step
process on how to read a paper, as well as a framework for performing a
literature review in a new field. This three step process involves a:&lt;/p>
&lt;ol>
&lt;li>Bird&amp;rsquo;s Eye View of the paper where only the Title, Abstract, Introduction,
Conclusion, and section and sub-section headings are read first,&lt;/li>
&lt;li>A deeper analysis of figures and content of the paper which involves finding
new, unread references to the reader and evaluating the quality of
illustrations to determine the quality of the paper,&lt;/li>
&lt;li>A virtual reimplementation of the paper where every claim of the paper is
analyzed and critiqued; typically this done by reviewers or those that are
doing a deeper analysis of the work.&lt;/li>
&lt;/ol>
&lt;p>I can see this process being useful for researchers as implementers of other&amp;rsquo;s
research must accomplish all three steps to properly appreciate and understand
what they need to do to perform their task. As for the literature review
framework, it involves utilizing academic search engines (e.g.
&lt;a href="https://https://scholar.google.com/">Google Scholar&lt;/a>) to find work within a
particular field, finding shared citations or authors within that field, then
evaluating top conferences within that field to see who the top researchers and
research topics are within that field. For exploratory research, this is both an
extremely simple and effective framework to follow and adapt to different
domains.&lt;/p>
&lt;p>However, S. Keshav does limit the reach of this paper by making it focus solely
on the woes of graduate students. This is inaccurate of the wider academic
readership, as more and more frequently undergraduate and industry professionals
are reading academic papers both for pleasure and for utilization in
assignments. This paper can easily become more inclusive of wider audiences
without changing the content in an updated version of this document. This would
make sense as the author has requested that this paper be treated as a living
document that can be subject to change as the author adapts his process and
framework for academic review.&lt;/p>
&lt;p>I would personally like to see this work be quantified in surveys and
implemented as artifacts that ensure that readers are properly following the
review method that the author has laid out.&lt;/p>
&lt;hr>
&lt;h2 id="summarization-technique">Summarization Technique&lt;/h2>
&lt;p>This paper was summarized using a modified technique proposed by S. Keshav in
his work &lt;em>How to Read a Paper&lt;/em> [0].&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/how-to-read-a-paper/</description></item></channel></rss>