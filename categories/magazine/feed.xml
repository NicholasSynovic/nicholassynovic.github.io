<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>magazine on Nicholas M. Synovic</title><link>https://nsynovic.dev/categories/magazine/</link><description>Recent content in magazine on Nicholas M. Synovic</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Nicholas M. Synovic</copyright><lastBuildDate>Mon, 20 Feb 2023 09:22:52 -0600</lastBuildDate><atom:link href="https://nsynovic.dev/categories/magazine/feed.xml" rel="self" type="application/rss+xml"/><item><title>A summary of Hidden Potential Within Video Game Consoles by Michael Mattioli et al.</title><link>https://nsynovic.dev/summaries/hidden-potential-within-video-game-consoles/</link><pubDate>Mon, 20 Feb 2023 09:22:52 -0600</pubDate><guid>https://nsynovic.dev/summaries/hidden-potential-within-video-game-consoles/</guid><description>&lt;h1 id="a-summary-of-hidden-potential-within-video-game-consoles">A summary of &lt;em>Hidden Potential Within Video Game Consoles&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Michael Mattioli et al.; IEEE Computing Edge, October 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-hidden-potential-within-video-game-consoles">A summary of &lt;em>Hidden Potential Within Video Game Consoles&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#performance">Performance&lt;/a>&lt;/li>
&lt;li>&lt;a href="#user-experience">User Experience&lt;/a>&lt;/li>
&lt;li>&lt;a href="#security">Security&lt;/a>&lt;/li>
&lt;li>&lt;a href="#cost">Cost&lt;/a>&lt;/li>
&lt;li>&lt;a href="#conclusion">Conclusion&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Video game consoles have many of the features desired for enterprise deployment.
They are also designed with security in mind, and are resilient against many
vulnerabilities.&lt;/p>
&lt;p>Video game consoles are cheap, security oriented, and reduce the total cost of
ownership (TCO) that a device has on an employee or organization.&lt;/p>
&lt;p>This article aims to compare different video game consoles for enterprise
deployment.&lt;/p>
&lt;h3 id="performance">Performance&lt;/h3>
&lt;p>Video game consoles, on release, are often more powerful than similarly priced
notebook PCs.&lt;/p>
&lt;h3 id="user-experience">User Experience&lt;/h3>
&lt;p>The consoles UI is defined to be easy to use. It is also easy to install and
perform simple service on some video game consoles.&lt;/p>
&lt;p>These devices are also versatile as any application can be written for the
console, however, development is dependent upon the video game consoles SDK.&lt;/p>
&lt;h3 id="security">Security&lt;/h3>
&lt;p>Video game consoles employ identity and access management through Sony,
Microsoft, and Nintendo logins for the PS4/5, Xbox Series, and Nintendo Switch
respectively.&lt;/p>
&lt;p>Video game consoles check and install security patches upon boot.&lt;/p>
&lt;p>Video game consoles are designed with both hardware and software security in
mind.&lt;/p>
&lt;h3 id="cost">Cost&lt;/h3>
&lt;p>Similarly designed notebook PCs cost nearly or more than twice as much as many
video game consoles upon their release.&lt;/p>
&lt;h3 id="conclusion">Conclusion&lt;/h3>
&lt;p>Video game consoles embody many of the criteria that is expected of an
enterprise grade notebook PCs.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/hidden-potential-within-video-game-consoles/</description></item><item><title>A summary of Whack-a-Meltdown by Daniel Genkin and Yuval Yarom</title><link>https://nsynovic.dev/summaries/whack-a-meltdown/</link><pubDate>Mon, 20 Feb 2023 08:34:58 -0600</pubDate><guid>https://nsynovic.dev/summaries/whack-a-meltdown/</guid><description>&lt;h1 id="a-summary-of-whack-a-meltdown">A summary of &lt;em>Whack-a-Meltdown&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Daniel Genkin and Yuval Yarom IEEE Computing Edge, October 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-whack-a-meltdown">A summary of &lt;em>Whack-a-Meltdown&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#out-of-order-execution">Out-Of-Order Execution&lt;/a>&lt;/li>
&lt;li>&lt;a href="#transient-execution-attacks">Transient Execution Attacks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#leaking-information-from-the-transient-domain">Leaking Information From The Transient Domain&lt;/a>&lt;/li>
&lt;li>&lt;a href="#first-generation-transient-execution-attacks">First-Generation Transient Execution Attacks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#defenses">Defenses&lt;/a>&lt;/li>
&lt;li>&lt;a href="#second-generation-attacks">Second-Generation Attacks&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>The Spectre and Meltdown vulnerabilities reported in 2018 exposed that there
exists side effects in speculative and out-of-order execution that allow for an
attacker to extract data from the micro architecture of a CPU. These and similar
attack patterns share a root cause - the micro architecture allowing to execute
code after an instruction fails. To resolve these issues, the straightforward
answer is to ensure that subsequent instructions do not use data produced by the
failed instruction. However, this is easier said than done and will take time to
implement. In the meantime, countermeasures put out by organizations - such as
Intel - only act as band aids that can quickly be bypassed.&lt;/p>
&lt;h3 id="out-of-order-execution">Out-Of-Order Execution&lt;/h3>
&lt;p>Out-of-order execution allows multiple computational units of a processor (known
as &lt;em>ports&lt;/em>) to run in parallel, each working on an individual instruction. This
is because some instructions take longer than others to complete. To keep track
of the instruction order, the processor maintains a reorder buffer (ROB) that
keeps track of the instructions and commits the results post instruction
completion. If the instruction fails, the ROB quashes the instruction. These
instructions are known as transient.&lt;/p>
&lt;p>However, there are a few issues with out-of-order execution:&lt;/p>
&lt;ol>
&lt;li>Misspeculation of instructions to run by incorrectly guessing the control
flow of the program.&lt;/li>
&lt;li>Exceptions when an instruction performs an illegal operation, causing the
program to abort. Future instructions are no longer part of the program.&lt;/li>
&lt;li>Microcode assists that handle complex edge cases require that the instruction
be thrown out and code from the processor firmware be used to handle that
case.&lt;/li>
&lt;li>&amp;ldquo;When a Transactional Synchronization Extension (TSX) transaction aborts, all
of the instructions within that transaction are not a part of the nominal
program execution.&amp;rdquo;&lt;/li>
&lt;/ol>
&lt;h3 id="transient-execution-attacks">Transient Execution Attacks&lt;/h3>
&lt;p>Transient execution attacks take advantage that while an instruction fails, the
state of the processor does not rollback to its previous state. Therefore,
memory addresses, cached data, and address translation are still in the
processor state post-transient instruction.&lt;/p>
&lt;h3 id="leaking-information-from-the-transient-domain">Leaking Information From The Transient Domain&lt;/h3>
&lt;p>Attackers will target the instruction cache post-transient instruction
execution. They will measure the amount of time it takes for a memory address to
be accessed. If it was quick, then the cache most likely has cached that data.&lt;/p>
&lt;h3 id="first-generation-transient-execution-attacks">First-Generation Transient Execution Attacks&lt;/h3>
&lt;p>Meltdown is a transient execution attack where the security between user and
kernel memory is bypassed. A user space program tries to access kernel memory
and fails, but the cache contains information from that attempted memory
address.&lt;/p>
&lt;p>Foreshadow takes advantage of Intel processors when they fail to resolve virtual
addresses to physical addresses. This attack targets the L1 processor cache.
Data can then be sampled from various secure enclaves.&lt;/p>
&lt;p>Fallout, RIDL, and ZombieLoad sample data from various caches using micro
architecture data sampling (MDS). They lack precision, but when repeatedly
targeted, the probability of getting important data increases.&lt;/p>
&lt;h3 id="defenses">Defenses&lt;/h3>
&lt;p>Intel and industry have released software security patches. Most of these
patches apply at OS level.&lt;/p>
&lt;p>The Kernel Page Table Isolation (KPTI) patch removes kernel space addresses from
the address space of processes thereby preventing user space programs from
performing lookups on kernel addresses.&lt;/p>
&lt;p>Page Table Entry (PTE) Inversion is a countermeasure against Foreshadow in which
the address space following transient execution does not point towards valid
page frames. Gang Scheduling is implemented by some VM hypervisors that ensure
that two hyper threads of a core always operate under the same protective
domain.&lt;/p>
&lt;p>Intel has released microcode to protect against MDS attacks. This includes
clearing the L1 cache when leaving the SGX enclave and an instruction to flush
the cache on a context switch.&lt;/p>
&lt;p>Additionally, new processors from Intel do not read across protective domains.
With this, KPTI protection can be disabled in order to regain lost performance.&lt;/p>
&lt;h3 id="second-generation-attacks">Second-Generation Attacks&lt;/h3>
&lt;p>The CacheOut attack takes advantage of the fact that L1 cache tends to end up in
the LFBs post cache flush, allowing data to be read from those locations.&lt;/p>
&lt;p>&amp;ldquo;The CrossTalk attack shows that data can be from a shared staging buffer can be
loaded to an leaked from LFBs, allowing attackers to compromise the SGX&amp;rsquo;s random
number generator.&amp;rdquo;&lt;/p>
&lt;p>The Load Value Injection (LVI) attack takes advantage of aborted instructions to
get around the cache flushing of data. This allows for an attacker to modify the
control flow of a program allowing for the execution of code not intended to be
ran.&lt;/p>
&lt;p>The authors recommend that to prevent these attacks in the future, micro
architecture designs will need to prevent execution of data dependent
instructions post aborted instructions. Alternatively, the processor will have
to modify the pipeline stages to not process invalid data.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/whack-a-meltdown/</description></item><item><title>A summary of COM-PACE: Compliance Aware Cloud Application Engineering Using Blockchain by Gagangeet Singh Aujla et al.</title><link>https://nsynovic.dev/summaries/com-pace-compliance-aware-cloud-application-engineering-using-blockchain/</link><pubDate>Sun, 19 Feb 2023 22:26:23 -0600</pubDate><guid>https://nsynovic.dev/summaries/com-pace-compliance-aware-cloud-application-engineering-using-blockchain/</guid><description>&lt;h1 id="a-summary-of-com-pace-compliance-aware-cloud-application-engineering-using-blockchain">A summary of &lt;em>COM-PACE: Compliance Aware Cloud Application Engineering Using Blockchain&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Gagangeet Singh Aujla et al. IEEE Computing Edge, October 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-com-pace-compliance-aware-cloud-application-engineering-using-blockchain">A summary of &lt;em>COM-PACE: Compliance Aware Cloud Application Engineering Using Blockchain&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#com-pace-architecture-for-hosting-services-in-a-multicloud-environment">COM-PACE Architecture For Hosting Services In A Multicloud Environment&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#compliance-provisioning">Compliance Provisioning&lt;/a>&lt;/li>
&lt;li>&lt;a href="#compliance-monitoring">Compliance Monitoring&lt;/a>&lt;/li>
&lt;li>&lt;a href="#compliance-verification-and-enforcement">Compliance Verification and Enforcement&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>This article proposes European General Data Protection Regulation (GDPR)
compliant cloud engineering practices in order to improve transparency of
personal data usage when using web services that are interlinked between one
another. For example, a website hosted on AWS that uses Google Adsense for
targeted advertisements and handles payment processing through Stripe.&lt;/p>
&lt;p>As web services depend on many providers, end users may not be aware of how much
or how their data is being is captured or used by providers or third parties
should that data be shared. The GDPR is intended to make it transparent to users
how this data is collected and shared.&lt;/p>
&lt;p>There are three terms that are often confused:&lt;/p>
&lt;ol>
&lt;li>Security - Refers to the resilience against potential harm from attackers&lt;/li>
&lt;li>Privacy - Refers to the with holding information from the largest number of
individuals with respect to personal data&lt;/li>
&lt;li>Compliance - Signifies the act of obeying a law or ruling&lt;/li>
&lt;/ol>
&lt;p>However, commercial cloud providers do not offer any promise of compliance with
any ruling or law. They do work to improve security, however, the companies that
use these services are required to maintain their own privacy guidelines. Given
the business of cloud providers who only offer a service for which others can
build tools on top of, it is difficult for them to understand the sensitivity of
data passing through their networks.&lt;/p>
&lt;h3 id="com-pace-architecture-for-hosting-services-in-a-multicloud-environment">COM-PACE Architecture For Hosting Services In A Multicloud Environment&lt;/h3>
&lt;p>COM-PACE is meant to be applied to a tradition Infrastructure as a Service
(IaaS) architecture while also encouraging the benefits of using multiple cloud
service providers.&lt;/p>
&lt;p>To follow the COM-PACE architecture, cloud developers must follow these three
programming steps and operations:&lt;/p>
&lt;ol>
&lt;li>Provisioning compliance at design and runtime - User data and organization
resources must be analyzed in tandem. Once these are known, data can be
appropriately provisioned between different tech stacks and/or cloud service
providers.&lt;/li>
&lt;li>Monitoring compliance at runtime - Monitoring checks for data leaks or
non-GDPR data operations occurring within the system. Events can then be
recorded to a block chain for logging and further analysis.&lt;/li>
&lt;li>Verifying and enforcing compliance at runtime - The block chain manager can
review all logged events and based on the event, can signal a violation or
critical error to the system administrators.&lt;/li>
&lt;/ol>
&lt;h4 id="compliance-provisioning">Compliance Provisioning&lt;/h4>
&lt;p>Current cloud service providers do not support end-to-end compliance support.
This has to be the first step on the cloud service providers end to encourage
more developers to seriously consider GDPR compliance. Data transmissions should
be handled over HTTPS and encrypted with AES-256.&lt;/p>
&lt;h4 id="compliance-monitoring">Compliance Monitoring&lt;/h4>
&lt;p>Current monitoring solutions do not fully encapsulate all of the metrics that
GDPR requires for compliance. Since cloud based services rely on virtual
machines or Docker containers to host software components, the granularity of
monitoring solutions needs to be fine grained. Additionally, depending upon the
component and where it is within the web stack, the monitoring solution needs to
multi-tiered to accommodate different metrics.&lt;/p>
&lt;p>There exists many challenges with monitoring solutions. These include the volume
of events and alert overloads, rule complexities, the architecture of complex
systems, auditing issues in clouds, and application migration in multicloud.
Monitoring solutions need to be able to keep up with and mitigate these issues.&lt;/p>
&lt;h4 id="compliance-verification-and-enforcement">Compliance Verification and Enforcement&lt;/h4>
&lt;p>Smart contracts can handle the verification and enforcement of GDPR of a system
on a block chain.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/com-pace-compliance-aware-cloud-application-engineering-using-blockchain/</description></item><item><title>A summary of Smart Contracts In The Global South by Nir Kshetri et al.</title><link>https://nsynovic.dev/summaries/smart-contracts-in-the-global-south/</link><pubDate>Sun, 19 Feb 2023 21:51:58 -0600</pubDate><guid>https://nsynovic.dev/summaries/smart-contracts-in-the-global-south/</guid><description>&lt;h1 id="a-summary-of-smart-contracts-in-the-global-south">A summary of &lt;em>Smart Contracts In the Global South&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Nir Kshetri et al. IEEE Computing Edge, October 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-smart-contracts-in-the-global-south">A summary of &lt;em>Smart Contracts In the Global South&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#contract-laws-and-their-enforcement-in-southern-countries">Contract Laws And Their Enforcement In Southern Countries&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#transaction-costs-associated-with-a-contract-in-southern-economies">Transaction costs Associated With a Contract in Southern Economies&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#smart-contracts-and-the-role-of-blockchain">Smart Contracts And The Role Of Blockchain&lt;/a>&lt;/li>
&lt;li>&lt;a href="#barriers-and-challenges">Barriers And Challenges&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;blockquote>
&lt;p>&amp;ldquo;Southern countries&amp;rdquo; refer to developing nations or countries.&lt;/p>
&lt;/blockquote>
&lt;p>Smart contracts are programs written on a blockchain that are executed once
certain conditions are met. These contracts could be used to enforce contract
laws and benefit economies in Southern countries.&lt;/p>
&lt;h3 id="contract-laws-and-their-enforcement-in-southern-countries">Contract Laws And Their Enforcement In Southern Countries&lt;/h3>
&lt;p>Formal contracts are legal documents that lay out the rights that parties are
entitled to, the rules they are bound to, and the punishments that they will
experience if they break any rules. Southern countries often do not engage in
formal contracts. Rather informal, repeat agreements are often enough to create
a sense of trust between parties. However, as economies improve, the need for
formal contracts arise as huge investments are often made to support the growth
of these economies.&lt;/p>
&lt;h4 id="transaction-costs-associated-with-a-contract-in-southern-economies">Transaction costs Associated With a Contract in Southern Economies&lt;/h4>
&lt;p>Both judicial misconduct and judicial error occur around the world. Judicial
misconduct is when a corruption-related action is taken by a judge. Judicial
error is when the courts make an error.&lt;/p>
&lt;h3 id="smart-contracts-and-the-role-of-blockchain">Smart Contracts And The Role Of Blockchain&lt;/h3>
&lt;p>Contracts are difficult to enforce outside of small communities in Southern
countries. Smart contracts were envisioned in the 1990s, but prior to the
blockchain were rarely utilized. Pre-blockchain smart contracts relied on cloud
computing, but in Southern countries, that might not be available or reliable.&lt;/p>
&lt;p>However, block chain based smart contracts work on a distributed network and can
be enforced as the rules and policies are described within the contract. These
smart contracts can be written above or on the block chain. Above the block
chain means that data is fed into the block chain. Whereas on the block chain
refers to the smart contract existing on the block chain. Regardless, smart
contracts require oracles that provide information outside of the block chain
into the smart contract to enact changes or code.&lt;/p>
&lt;h3 id="barriers-and-challenges">Barriers And Challenges&lt;/h3>
&lt;p>Currently, there are not block chain specific or governing bodies that are
standardizing or regulating smart contracts. It might not be possible to
regulate or standardize smart contracts as well.&lt;/p>
&lt;p>Large populations within Southern countries lack internet access, making smart
contracts difficult to enact in the first place. There is also a general lack of
blockchain developers and engineers.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/smart-contracts-in-the-global-south/</description></item><item><title>A summary of Supercomputing In Python With Legate by Michael Bauer et al.</title><link>https://nsynovic.dev/summaries/supercomputing-in-python-with-legate/</link><pubDate>Sun, 19 Feb 2023 21:34:36 -0600</pubDate><guid>https://nsynovic.dev/summaries/supercomputing-in-python-with-legate/</guid><description>&lt;h1 id="a-summary-of-supercomputing-in-python-with-legate">A summary of &lt;em>Supercomputing In Python With Legate&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Michael Bauer et al. IEEE Computing Edge, October 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-supercomputing-in-python-with-legate">A summary of &lt;em>Supercomputing In Python With Legate&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#supercomputing-with-numpy">Supercomputing With Numpy&lt;/a>&lt;/li>
&lt;li>&lt;a href="#programming-system">Programming System&lt;/a>&lt;/li>
&lt;li>&lt;a href="#composable-ecosystem">Composable Ecosystem&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Numpy and Pandas are software packages that aid in the development of
mathematical software because their notations mimic that of scientific and
mathematical notation. However, neither package scales to modern HPC. Thus
Legate was developed to mimic the interfaces that both Numpy and Pandas provide
while being able to scale to many computing resources.&lt;/p>
&lt;h3 id="supercomputing-with-numpy">Supercomputing With Numpy&lt;/h3>
&lt;p>Numpy syntax is compact and able to concisely express mathematical operations.
Additionally, Numpy operations offer themselves to parallelization easily.
However, vanilla Numpy doesn&amp;rsquo;t natively support these parallelization
optimizations. Therefore a number of efforts exist to implement these
optimizations. Legate supports these operations and fall backs to single-core
performance when it doesn&amp;rsquo;t.&lt;/p>
&lt;p>Legate defines a common data model that can be used to expand Numpy&amp;rsquo;s memory
allocation and library extensions.&lt;/p>
&lt;p>Legate&amp;rsquo;s extensions to Numpy provide access to data parallel operations that
vanilla Numpy and similar alternatives to Legate don&amp;rsquo;t offer.&lt;/p>
&lt;h3 id="programming-system">Programming System&lt;/h3>
&lt;p>Legate is built on top of Legion, which acts as a dynamic programming system for
HPC. When a call is made from Legate, Legion is able to interpret this code and
distribute it to many nodes. Legion may also reorder Legate calls for better
performance.&lt;/p>
&lt;p>This was done to avoid compiling Legate-Numpy code into an optimized program for
HPC.&lt;/p>
&lt;h3 id="composable-ecosystem">Composable Ecosystem&lt;/h3>
&lt;p>Legate aims to be a building block for other Numpy based libraries to be based
off of. As an example of this, Legate Pandas was created as a Pandas alternative
complete with parallelization optimizations.&lt;/p>
&lt;p>An advantage of building off of Legate and Legion is that the communication and
protocol layer already exist, thereby allowing developers to easily extend these
applications to their respective purposes.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/supercomputing-in-python-with-legate/</description></item><item><title>A summary of Interactive Supercomputing With Jupyter by Rollin Thomas et al.</title><link>https://nsynovic.dev/summaries/interactive-supercomputing-with-jupyter/</link><pubDate>Sun, 19 Feb 2023 20:40:07 -0600</pubDate><guid>https://nsynovic.dev/summaries/interactive-supercomputing-with-jupyter/</guid><description>&lt;h1 id="a-summary-of-interactive-supercomputing-with-jupyter">A summary of &lt;em>Interactive Supercomputing With Jupyter&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Rollin Thomas et al.; IEEE Computing Edge, October 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-interactive-supercomputing-with-jupyter">A summary of &lt;em>Interactive Supercomputing With Jupyter&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#how-it-started-and-how-its-going">How It Started And How It&amp;rsquo;s Going&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#phase-1-jupyterhub-as-science-gateway">Phase 1: JupyterHub as Science Gateway&lt;/a>&lt;/li>
&lt;li>&lt;a href="#phase-2-jupyter-on-a-cori-login-node">Phase 2: Jupyter on a Cori Login Node&lt;/a>&lt;/li>
&lt;li>&lt;a href="#phase-3-jupyter-as-interface-to-an-hpc-center">Phase 3: Jupyter as Interface to an HPC Center&lt;/a>&lt;/li>
&lt;li>&lt;a href="#phase-4-jupyterlab-as-innovation-platform">Phase 4: JupyterLab as Innovation Platform&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#jupyter--hpc--science">Jupyter + HPC = Science!&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>The Jupyter project has the potential to allow other scientific domains to
utilize supercomputing resources in an accessible manner. The National Energy
Research Scientific Computing Center (NERSC) has implemented a Jupyter interface
into their Cori supercomputer. This interface now captures 20% - 25% of user
traffic when working on Cori.&lt;/p>
&lt;h3 id="how-it-started-and-how-its-going">How It Started And How It&amp;rsquo;s Going&lt;/h3>
&lt;p>In 2015, NERSC recognized that a growing number of users were using SSH to run
their Jupyter notebooks on the previous generation Edison supercomputer. As
such, NERSC began looking into how to incorporate Jupyter notebooks as a
standard interface into Cori.&lt;/p>
&lt;h4 id="phase-1-jupyterhub-as-science-gateway">Phase 1: JupyterHub as Science Gateway&lt;/h4>
&lt;p>NERSC implemented a separate hardware solution to host JupyterHub. This
JupyterHub instance allowed users to store their notebooks on the NERSC Global
Filesystem (NGF), which allowed teams and individuals to collaborate and run
shared notebooks.&lt;/p>
&lt;h4 id="phase-2-jupyter-on-a-cori-login-node">Phase 2: Jupyter on a Cori Login Node&lt;/h4>
&lt;p>Jupyter was than ran on login nodes with outputs piped to computation nodes. The
architecture and hosting of both the Jupyter and JupyterHub instances kept
changing hardware and which confused end users.&lt;/p>
&lt;h4 id="phase-3-jupyter-as-interface-to-an-hpc-center">Phase 3: Jupyter as Interface to an HPC Center&lt;/h4>
&lt;p>JupyterHub was moved to a Docker container and hosted on Cori. It now acts as
the single point of access for running Jupyter notebooks on Cori, specialty
servers, and staff only test servers.&lt;/p>
&lt;h4 id="phase-4-jupyterlab-as-innovation-platform">Phase 4: JupyterLab as Innovation Platform&lt;/h4>
&lt;p>JupyterLab is a product from the Jupyter project aimed at collaboration and
provides many improvements on top of the standard Jupyter project. Such
improvements include better file system navigation and reusability and
reproducibility of notebook experiments. NERSC has created a number of
extensions to support JupyterLab on Cori, including file system navigation
extensions, and &lt;code>jupyterlab-slurm&lt;/code> for adding &lt;code>SLURM&lt;/code> job scheduling directly
within JupyterLab.&lt;/p>
&lt;h3 id="jupyter--hpc--science">Jupyter + HPC = Science!&lt;/h3>
&lt;p>A number of disciplines now rely on Jupyter to perform calculations on the Cori
supercomputer. These include:&lt;/p>
&lt;ul>
&lt;li>Geophysical Subsurface Imaging&lt;/li>
&lt;li>Electron Microscope Image Analysis&lt;/li>
&lt;li>Advanced Light Source Tomography&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/interactive-supercomputing-with-jupyter/</description></item><item><title>A summary of Automated Payment Terminal Testing: How to Achieve Continuous Integration for Systems that are Almost Impossible to Virtualize by Martin Gloor et al.</title><link>https://nsynovic.dev/summaries/automated-payment-terminal-testing-how-to-achieve-continuous-integration-for-systems-that-are-almost-impossible-to-virtualize/</link><pubDate>Sun, 19 Feb 2023 15:42:36 -0600</pubDate><guid>https://nsynovic.dev/summaries/automated-payment-terminal-testing-how-to-achieve-continuous-integration-for-systems-that-are-almost-impossible-to-virtualize/</guid><description>&lt;h1 id="a-summary-of-automated-payment-terminal-testing-how-to-achieve-continuous-integration-for-systems-that-are-almost-impossible-to-virtualize">A summary of &lt;em>Automated Payment Terminal Testing: How to Achieve Continuous Integration for Systems that are Almost Impossible to Virtualize&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Martin Gloor et al. IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-automated-payment-terminal-testing-how-to-achieve-continuous-integration-for-systems-that-are-almost-impossible-to-virtualize">A summary of &lt;em>Automated Payment Terminal Testing: How to Achieve Continuous Integration for Systems that are Almost Impossible to Virtualize&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#shift-left-of-die---or-why-are-we-doing-this">Shift Left of Die - Or, Why are We Doing This?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#to-virtualize-or-not-to-virtualize">To Virtualize or Not To Virtualize&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-journey-of-trial-and-error">A Journey of Trial and Error&lt;/a>&lt;/li>
&lt;li>&lt;a href="#scaling-with-cards">Scaling With Cards&lt;/a>&lt;/li>
&lt;li>&lt;a href="#coping-with-calibration">Coping With Calibration&lt;/a>&lt;/li>
&lt;li>&lt;a href="#apis-and-abstraction-layers">APIs and Abstraction Layers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#generic-but-not">Generic, But Not!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#habemus-automation">Habemus Automation!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-continuous-journey">A Continuous Journey&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Pure software solutions benefit from continuous integration platforms. However,
solutions that involve both hardware and software - such as payment terminals -
need to develop custom continuous integration platforms that test both
components in order to meet modern Agile development practices.&lt;/p>
&lt;h3 id="shift-left-of-die---or-why-are-we-doing-this">Shift Left of Die - Or, Why are We Doing This?&lt;/h3>
&lt;p>Since Abrantix (the company the authors work at) design and development payment
terminal systems, they typically test end-to-end solutions with human testers.
However, as tests involve many repetitive tasks, human error and fatigue can
invalidate many tests. Therefore, they needed to develop an automated platform
to not only handle software testing and continuous integration, but also
hardware testing and integration. In doing so, they aim to catch bugs earlier in
the development cycle, reduce human error, and run regression testing all
autonomously.&lt;/p>
&lt;h3 id="to-virtualize-or-not-to-virtualize">To Virtualize or Not To Virtualize&lt;/h3>
&lt;p>While it is possible to abstract hardware interfaces virtually, there is
difficulty in virtualizing some actions that need to be tested. For example:&lt;/p>
&lt;ul>
&lt;li>Card readers are hard to mock as they need to test magstripe, contactless and
contact chip payments, and the Eurocard, MasterCard, Visa (EMV) standard would
need to be virtualized as well.&lt;/li>
&lt;li>Secure modules are hard to mock as the required cryptographic functions are
often proprietary, can involve both symmetric and asymmetric keys, and have to
comply with rigorous standards.&lt;/li>
&lt;li>No real end-to-end testing of hardware and software is tested.&lt;/li>
&lt;/ul>
&lt;h3 id="a-journey-of-trial-and-error">A Journey of Trial and Error&lt;/h3>
&lt;p>Abrantix decided to go with a robot to solve the end-to-end hardware and
software testing. They started with a cheap robotic arm and found that it was
capable of handling both contactless and contact based chip solutions, but was
unable to enter PIN codes. They therefore pivoted to a 3D printed solution to
enter PIN codes and to drop the robotic arm solution.&lt;/p>
&lt;h3 id="scaling-with-cards">Scaling With Cards&lt;/h3>
&lt;p>To scale with multiple cards, a multiplexer was built to handle inputs from
multiple different cards into a single output.&lt;/p>
&lt;h3 id="coping-with-calibration">Coping With Calibration&lt;/h3>
&lt;p>In order to calibrate the robot for each terminal, a layout of each terminal was
made and a user could select what terminal to test. It was therefore on the user
to swap in and out the terminals for each test. This way a single test could be
written and abstracted away from the terminal interface.&lt;/p>
&lt;h3 id="apis-and-abstraction-layers">APIs and Abstraction Layers&lt;/h3>
&lt;p>At this point the base end-to-end testing solution was built. However, as the
solution scaled to meet the demands of the company and partners, it became
apparent that the software architecture couldn&amp;rsquo;t handle all of the requested
features. Therefore, abstraction layers were written and a REST HTTP API
interface was created to simplify both the development of the software solution
as well as to allow third party orchestration tools to hook into the state of
the testing solution.&lt;/p>
&lt;h3 id="generic-but-not">Generic, But Not!&lt;/h3>
&lt;p>To allow for control of the robotic testing platform as well as to provide
extensibility to the REST API, a schema based on JSON was developed that can be
used to control the robot.&lt;/p>
&lt;h3 id="habemus-automation">Habemus Automation!&lt;/h3>
&lt;p>Now that the testing solution had been developed, a stress test of running 5,000
transactions on individual terminals was ran. 70 bugs were found on average per
terminal model. These bugs couldn&amp;rsquo;t have been found in such a short time without
the development of this tool.&lt;/p>
&lt;h3 id="a-continuous-journey">A Continuous Journey&lt;/h3>
&lt;p>There a number of security concerns and procedures not currently implemented in
the testing solution. However, Abrantix is intending to continue the development
of this solution and iterate upon, just as any developer would working with
continuous integration.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/automated-payment-terminal-testing-how-to-achieve-continuous-integration-for-systems-that-are-almost-impossible-to-virtualize/</description></item><item><title>A summary of Toward Fail Safety for Security Decisions by Trent Jaeger</title><link>https://nsynovic.dev/summaries/toward-fail-safety-for-security-decisions/</link><pubDate>Sun, 19 Feb 2023 13:39:57 -0600</pubDate><guid>https://nsynovic.dev/summaries/toward-fail-safety-for-security-decisions/</guid><description>&lt;h1 id="a-summary-of-toward-fail-safety-for-security-decisions">A summary of &lt;em>Toward Fail Safety for Security Decisions&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Trent Jaeger IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-toward-fail-safety-for-security-decisions">A summary of &lt;em>Toward Fail Safety for Security Decisions&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#examples-of-how-user-decisions-impact-security">Examples of How User Decisions Impact Security&lt;/a>&lt;/li>
&lt;li>&lt;a href="#a-design-goal-fail-safe-decisions">A Design Goal: Fail-Safe Decisions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#using-fail-safety-effectively">Using Fail Safety Effectively&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Developers of technologies aim to automate security decisions on behalf of the
consumer. However, security decisions made by end users are often ad-hoc and
unguided. As researchers, we should figure out how to create systems that are
reduce vulnerabilities when poor manual choices are made.&lt;/p>
&lt;h3 id="examples-of-how-user-decisions-impact-security">Examples of How User Decisions Impact Security&lt;/h3>
&lt;p>Mobile applications often request access to sensors on the device to operate.
However, it is often unclear as to why these applications want to utilize these
sensors. Additionally, by granting security access to malicious apps, it is
possible for the apps to modify core system functionality or compromise core
processes for their own gain.&lt;/p>
&lt;p>Within the IoT space, often developers let the end users handle the security
permissions on their end. However, it is both the developers and the end-users
job to ensure that the devices are operating within in a secure environment.&lt;/p>
&lt;h3 id="a-design-goal-fail-safe-decisions">A Design Goal: Fail-Safe Decisions&lt;/h3>
&lt;p>We should have fail-safe defaults that expresses the permissions that a device
or application has rather than what it doesn&amp;rsquo;t. In other words, return positive
feedback as to the what an application or device can do, rather than what it
can&amp;rsquo;t.&lt;/p>
&lt;p>To support this, applications need to help users make better decisions. This
could be done through supporting safe choices through the path of least
resistance. In other words, make it easy to secure an application and difficult
to disable security. However, it is difficult for programmers to decide what is
and isn&amp;rsquo;t a safe decision.&lt;/p>
&lt;h3 id="using-fail-safety-effectively">Using Fail Safety Effectively&lt;/h3>
&lt;p>If fail safety is implemented on a per device level, it won&amp;rsquo;t be able to scale
to entire technology sectors. Therefore, best practices need to be developed in
order to allow fail-safety to grow.&lt;/p>
&lt;p>However, as legacy applications did not focus on information-flow integrity, it
might be impossible to back port fail safety to legacy applications.&lt;/p>
&lt;p>Furthermore, research needs to be done on how to identify when manual security
changes expose applications to security vulnerabilities. This way programmers
and researchers can devise new methods of protecting the end user when they
disable security features.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/toward-fail-safety-for-security-decisions/</description></item><item><title>A summary of Pervasive Security and Privacy by - A Brief Reflection on Challenges and Opportunities by Florian Alt</title><link>https://nsynovic.dev/summaries/pervasive-security-and-privacy-a-brief-reflection-on-challenges-and-opportunities/</link><pubDate>Sun, 19 Feb 2023 10:56:20 -0600</pubDate><guid>https://nsynovic.dev/summaries/pervasive-security-and-privacy-a-brief-reflection-on-challenges-and-opportunities/</guid><description>&lt;h1 id="a-summary-of-pervasive-security-and-privacy-by---a-brief-reflection-on-challenges-and-opportunities">A summary of &lt;em>Pervasive Security and Privacy by - A Brief Reflection on Challenges and Opportunities&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Florian Alt IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-pervasive-security-and-privacy-by---a-brief-reflection-on-challenges-and-opportunities">A summary of &lt;em>Pervasive Security and Privacy by - A Brief Reflection on Challenges and Opportunities&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#the-state-of-security-and-privacy-in-pervasive-computing">The State of Security and Privacy in Pervasive Computing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#implications">Implications&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#security-and-privacy-decision-overload">Security and Privacy Decision Overload&lt;/a>&lt;/li>
&lt;li>&lt;a href="#unawareness-of-data-sensitivity">Unawareness of Data Sensitivity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sensing-close-to-the-body">Sensing Close to the Body&lt;/a>&lt;/li>
&lt;li>&lt;a href="#unclear-flow-of-data">Unclear Flow of Data&lt;/a>&lt;/li>
&lt;li>&lt;a href="#multidevice-environments">Multidevice Environments&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#challenges-and-opportunities">Challenges and Opportunities&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#designing-appropriate-mechanisms">Designing Appropriate Mechanisms&lt;/a>&lt;/li>
&lt;li>&lt;a href="#involvement-of-different-stakeholders">Involvement of Different Stakeholders&lt;/a>&lt;/li>
&lt;li>&lt;a href="#out-of-the-box-security-and-privacy">Out-of-the-Box Security and Privacy&lt;/a>&lt;/li>
&lt;li>&lt;a href="#adaptive-security-and-privacy-mechanisms">Adaptive security and Privacy Mechanisms&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Pervasive computing developments open up the opportunity for different human
experiences and research. However, security and privacy methods must take into
account what these new developments bring to the table; including both the
positives and the negatives of such computing. With this technology, user states
and contexts can be more easily inferred as well as their emotional and
cognitive states.&lt;/p>
&lt;p>This article is meant to give an overview of the challenges and opportunities
that arise within the security and privacy domain of pervasive computing.&lt;/p>
&lt;h3 id="the-state-of-security-and-privacy-in-pervasive-computing">The State of Security and Privacy in Pervasive Computing&lt;/h3>
&lt;p>The &lt;em>mainframe era&lt;/em> involved securing the intellectual rights of technologies
stored on big iron. The &lt;em>personal computing era&lt;/em> involved securing protecting
the privacy and data of everyday users. The &lt;em>pervasive computing era&lt;/em> will
involve protecting all of the data generating and capturing devices that a user
not only owns but interacts with.&lt;/p>
&lt;p>Pervasive computing includes both traditional computing devices, but also edge
devices, smart devices and appliances, and internet software. Pervasive
computing allows for sensitive data to be accessed both locally and remotely,
and therefore presents new challenges w.r.t security and privacy.&lt;/p>
&lt;p>Boundaries between domains are changing. For example, their used to be a barrier
between work and home, but with the COVID-19 pandemic, work and home became one.
This opened the doors to new attack vectors as it became more common for people
to work from home.&lt;/p>
&lt;h3 id="implications">Implications&lt;/h3>
&lt;h4 id="security-and-privacy-decision-overload">Security and Privacy Decision Overload&lt;/h4>
&lt;p>As we interface with more and more computers, we (as users) become overloaded
with different authentication schemes and practices. Additionally, all of the
devices that we interact with have many different privacy permissions and
options that the user might not be aware of and therefore enable or disable.&lt;/p>
&lt;h4 id="unawareness-of-data-sensitivity">Unawareness of Data Sensitivity&lt;/h4>
&lt;p>It is possible to generate many data points about an individual from a single
sensor. Therefore, it is imperative that users not only know about these
different data points, but also the implications for each data point. However,
it is currently very difficult to inform users of the importance of each data
point.&lt;/p>
&lt;h4 id="sensing-close-to-the-body">Sensing Close to the Body&lt;/h4>
&lt;p>Many of the &lt;a href="#unawareness-of-data-sensitivity">data sensitivity problems&lt;/a> arises
from users wearing sensors close to the body. These sensors can pick up on
health related information about an individual. Current sensor providers do very
little to protect this information. Therefore figuring out methods of obscuring
or reducing the collection of such information is important.&lt;/p>
&lt;h4 id="unclear-flow-of-data">Unclear Flow of Data&lt;/h4>
&lt;p>It is very difficult to understand where all of the data from internet of things
(IoT) devices is being stored. Thus the flow of data from a sensor to the
end-user is unclear. What data goes to the cloud? What stays locally? How is
data accessed? Who can access that data? How is it processed? Which data is
being collected? Novel solutions (i.e., privacy labels/badges) must be developed
to answer these questions to protect consumers.&lt;/p>
&lt;h4 id="multidevice-environments">Multidevice Environments&lt;/h4>
&lt;p>There is a push by hardware and software developers to integrate experiences
tightly together via multidevice communication. For example, logging into
Netflix on a smart TV through your cell phone. However, these multidevice
experiences raise security and privacy concerns as there are more points of
failure and attack vectors as the number of devices involved scales.&lt;/p>
&lt;h3 id="challenges-and-opportunities">Challenges and Opportunities&lt;/h3>
&lt;h4 id="designing-appropriate-mechanisms">Designing Appropriate Mechanisms&lt;/h4>
&lt;p>Better security interfaces need to be designed to promote users to protect their
data. Furthermore, good enough security practices (i.e., password
authentication) need to be revisited to see if and where areas of improvement
need to occur to better protect end users.&lt;/p>
&lt;h4 id="involvement-of-different-stakeholders">Involvement of Different Stakeholders&lt;/h4>
&lt;p>The end user is not the enemy with respect to security. Therefore, pervasive
computing technologies and experiences need to take into account the security
practices and limitations that end users experience and accommodate that. For
example, replacing password authentication with bio-metrics.&lt;/p>
&lt;h4 id="out-of-the-box-security-and-privacy">Out-of-the-Box Security and Privacy&lt;/h4>
&lt;p>Pervasive computing technologies need to be secure out-of-the-box and involve
very little user interaction to enable sensible security and privacy settings.&lt;/p>
&lt;h4 id="adaptive-security-and-privacy-mechanisms">Adaptive security and Privacy Mechanisms&lt;/h4>
&lt;p>Pervasive computing can allow for authentication schemes based on the state of
the user. However, this information must simultaneously be protected and secured
in order to prevent data leaks.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/pervasive-security-and-privacy-a-brief-reflection-on-challenges-and-opportunities/</description></item><item><title>A summary of Economics of Artificial Intelligence in Cybersecurity by Nir Kshetri</title><link>https://nsynovic.dev/summaries/economics-of-artificial-intelligence-in-cybersecurity/</link><pubDate>Sun, 19 Feb 2023 10:16:22 -0600</pubDate><guid>https://nsynovic.dev/summaries/economics-of-artificial-intelligence-in-cybersecurity/</guid><description>&lt;h1 id="a-summary-of-economics-of-artificial-intelligence-in-cybersecurity">A summary of &lt;em>Economics of Artificial Intelligence in Cybersecurity&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Nir Kshetri IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-economics-of-artificial-intelligence-in-cybersecurity">A summary of &lt;em>Economics of Artificial Intelligence in Cybersecurity&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#current-state-of-ai-in-cybersecurity-and-key-areas-being-transformed">Current State of AI in Cybersecurity and Key Areas Being Transformed&lt;/a>&lt;/li>
&lt;li>&lt;a href="#key-factors-driving-ais-use-in-cybersecurity">Key Factors Driving AI&amp;rsquo;s Use in Cybersecurity&lt;/a>&lt;/li>
&lt;li>&lt;a href="#some-shortcomings-limitations-and-challenges">Some Shortcomings, Limitations, and Challenges&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>AI in cybersecurity is a growing market estimated to reach $101.8 billion by
2030.&lt;/p>
&lt;p>As the internet was designed &lt;strong>without&lt;/strong> security in mind, their exists an
asymmetric where small organizations or individuals can comprise large groups,
companies, or nation states. Therefore, defense mechanisms must be in place to
stop these attacks. Since defendants have access to a large corpus of malware
examples, it is possible to train AI models to defend against attacks.&lt;/p>
&lt;h3 id="current-state-of-ai-in-cybersecurity-and-key-areas-being-transformed">Current State of AI in Cybersecurity and Key Areas Being Transformed&lt;/h3>
&lt;p>AI is often faster at detecting malware than humans. Additionally, it is also
faster at containing infected devices on a network than a human. Furthermore, AI
can lower the cost of detecting malware.&lt;/p>
&lt;p>Traditional antivirus programs rely on a database of malware examples to check
against. However, AI can learn the representations of malware and then find new
malware examples prior to them being added to a database. Thus, it is possible
for AI to stop zero-day vulnerabilities by recognizing the representation of
malware during or prior to the attack.&lt;/p>
&lt;p>However, security experts recommend taking an augmented intelligence approach
with AI security. This involves a human-AI partnership in identifying and acting
upon threats. This is because current AI techniques are not accurate or advanced
enough to entirely replace a human security professional.&lt;/p>
&lt;p>AI has already been used to stop advance attacks from foreign, state run
organizations (i.e., APT41) and more common attacks.&lt;/p>
&lt;p>AI is already in use to detect anomalies in identity and access security. It is
possible for an AI to monitor and make decisions based off of an accounts
activity. As an example, Facebook uses an AI-powered deep entity classification
(DEC) to determine if an account is fraudulent or not. If so, the account is
removed from Facebook. This tool was used to crack down on fake accounts and
accounts that utilized deep fakes.&lt;/p>
&lt;p>AI cybersecurity software is being used by academic institutions as attackers
are increasingly targeting universities and academic institutions. These tools
have been successful in stopping or preventing cyber threats on students, staff,
and networks.&lt;/p>
&lt;h3 id="key-factors-driving-ais-use-in-cybersecurity">Key Factors Driving AI&amp;rsquo;s Use in Cybersecurity&lt;/h3>
&lt;p>The cost of AI cybersecurity tools is dropping both for consumers and for
enterprises. There exists more publicly available and enterprise-only datasets
for training AI to detect malware. And there is a shortage of cybersecurity
professionals entering the workforce, so AI could be used to address this
shortage of staff.&lt;/p>
&lt;h3 id="some-shortcomings-limitations-and-challenges">Some Shortcomings, Limitations, and Challenges&lt;/h3>
&lt;p>There exists several shortcomings with using AI cybersecurity tools. For
starters, it is difficult to explain what the tool is doing. Security
professionals therefore prefer an, &amp;ldquo;Explainable First, Predictive Second&amp;rdquo; [1]
approach to AI tools. Additionally, AI tools can not make security related
decisions without human interventions.&lt;/p>
&lt;p>And as AI tools grow in popularity, bias will start to develop within these
tools. This could potentially allow an attacker to exploit this bias and write
malware that is not detected by the tool.&lt;/p>
&lt;p>Furthermore, it is uncertain how AI tools would handle volatile situations, such
as the COVID-19 pandemic. As such, cybersecurity professionals might turn &lt;em>off&lt;/em>
or raise the detection threshold on these tools during such situations,
potentially allowing attacks to slip through.&lt;/p>
&lt;p>Finally, not all of the necessary data to properly train these tools is
available due to federal regulation. Personally identifying information (PII)
cannot be made publicly available for the purposes of training. Additionally, it
is assumed that large &amp;ldquo;data lakes&amp;rdquo; of Americans exist under the control of
foreign entities. It is therefore possible for an entity to utilize one of these
data lakes to write attacks that would not be detected as the attack is coming
from an American rather than a foreign entity.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/economics-of-artificial-intelligence-in-cybersecurity/</description></item><item><title>A summary of Sentiment Analysis and Topic Recognition in Video Transcripts by Lukas Stappen et al.</title><link>https://nsynovic.dev/summaries/sentiment-analysis-and-topic-recognition-in-video-transcripts/</link><pubDate>Sat, 18 Feb 2023 19:03:11 -0600</pubDate><guid>https://nsynovic.dev/summaries/sentiment-analysis-and-topic-recognition-in-video-transcripts/</guid><description>&lt;h1 id="a-summary-of-sentiment-analysis-and-topic-recognition-in-video-transcripts">A summary of &lt;em>Sentiment Analysis and Topic Recognition in Video Transcripts&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Lukas Stappen et al. Posted in IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-sentiment-analysis-and-topic-recognition-in-video-transcripts">A summary of &lt;em>Sentiment Analysis and Topic Recognition in Video Transcripts&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#related-work">Related Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#methodology">Methodology&lt;/a>&lt;/li>
&lt;li>&lt;a href="#dataset-the-muse-topic-subchallenge">Dataset: The MuSe-Topic Subchallenge&lt;/a>&lt;/li>
&lt;li>&lt;a href="#exploratory-analysis">Exploratory Analysis&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#speaker-topics">Speaker Topics&lt;/a>&lt;/li>
&lt;li>&lt;a href="#emotions">Emotions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#prediction-results">Prediction Results&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#speaker-topics-1">Speaker Topics&lt;/a>&lt;/li>
&lt;li>&lt;a href="#emotions-1">Emotions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>It is difficult to extract the sentiment and topic from a video transcript. With
this in mind, researchers developed SenticNet [2], a natural language
processing (NLP) model to identify the sentiment and topic of a transcript with
far less computational resources than previous attempts. The authors were able
to achieve 3% better performance than previous solutions for the MuSe
competition.&lt;/p>
&lt;p>Multi-model sentiment analysis (MSA) is taking a variety of data streams and
information types and extracting sentiment from them. MSA research aims to
understand the sentiment holder, emotional disposition, and the reference
object. MSA typically works on video data as it includes visual (e.g., facial
expressions), audio, and textual (e.g., transcripts) data modalities.
Transcripts have been found to provide the greatest impact in understanding the
topic at hand.&lt;/p>
&lt;p>The authors solution learned a continuous vector space of embeddings from the
symbolic space of words from the transcripts. To identify sentiments, their
solution adheres to the description of of sentiments defined by the &lt;em>Hourglass
of Emotions&lt;/em> [1].&lt;/p>
&lt;h3 id="related-work">Related Work&lt;/h3>
&lt;p>Human communication is a symbolic and naturally ordered within a structured
hierarchy. Current solutions to identifying sentiment from human communication
rely on synsets which are labels that indicate emotion and mood categories.
SenticNet has the largest amount of synsets with 200,000 concepts map words to a
sentiment.&lt;/p>
&lt;p>Automated sentiment and aspect extraction is of interest within the MSA field.
Current solutions involve hand crafted features. The authors applied
&amp;ldquo;commonsense knowledge&amp;rdquo; about topic extraction involving several sentences.&lt;/p>
&lt;h3 id="methodology">Methodology&lt;/h3>
&lt;p>First, natural world concepts are obtained using SenticNet. Versions 5 and 6 of
SenticNet were used as both extracted different sentics. Stop words were
removed. A linear SVM was applied on the vector word embeddings to predict the
valence, arousal, and topics of the transcript. To improve the generalization
between the feature maps, embedding dropout was used as well as time-step
dropout in order to drop entire embeddings rather than features.&lt;/p>
&lt;h3 id="dataset-the-muse-topic-subchallenge">Dataset: The MuSe-Topic Subchallenge&lt;/h3>
&lt;p>The MuSe-CaR [3] dataset is a large, multi-modal dataset consisting of YouTube
videos of car reviews. The purpose of the dataset is to support MSA research.&lt;/p>
&lt;p>The authors only used the language modality of the dataset and ignored the video
and audio modality. Recent advances in speech to text technologies have resulted
in near human performance.&lt;/p>
&lt;p>For the MuSe-Topic challenge, the weighted score of the combination of the
unweighted average recall and micro F1 measures for each prediction (valence,
arousal, and topic) was reported.&lt;/p>
&lt;h3 id="exploratory-analysis">Exploratory Analysis&lt;/h3>
&lt;h4 id="speaker-topics">Speaker Topics&lt;/h4>
&lt;p>The concepts of semantics were used to identify the contextual information of
the video. These were used to understand the characteristic properties of the
video.&lt;/p>
&lt;h4 id="emotions">Emotions&lt;/h4>
&lt;p>SenticNet was used in an unsupervised fashion to identify the emotions of the
video from the contextual information.&lt;/p>
&lt;h3 id="prediction-results">Prediction Results&lt;/h3>
&lt;h4 id="speaker-topics-1">Speaker Topics&lt;/h4>
&lt;p>The best performance measured achieved a score of 66.16% on the test dataset.
This was better than the LSTM approach the authors also tried. However, Albert
(an end-2-end NLP transformer for supervised NLP tasks) [4] still outperforms
this solution.&lt;/p>
&lt;h4 id="emotions-1">Emotions&lt;/h4>
&lt;p>SenticNet version 6 outperforms version 5 when identifying emotions.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/sentiment-analysis-and-topic-recognition-in-video-transcripts/</description></item><item><title>A summary of Advances in Human Activity Recognition by Gulustan Dogan</title><link>https://nsynovic.dev/summaries/advances-in-human-activity-recognition/</link><pubDate>Sat, 18 Feb 2023 18:51:36 -0600</pubDate><guid>https://nsynovic.dev/summaries/advances-in-human-activity-recognition/</guid><description>&lt;h1 id="a-summary-of-advances-in-human-activity-recognition">A summary of &lt;em>Advances in Human Activity Recognition&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Gulustan Dogan IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-advances-in-human-activity-recognition">A summary of &lt;em>Advances in Human Activity Recognition&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#this-method-is-great-when-working-on-raw-data-streams-but-there-do-exist-better-algorithms-and-models-to-handle-visual-representations-of-movement">This method is great when working on raw data streams, but there do exist better algorithms and models to handle visual representations of movement.&lt;/a>&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Human activity recognition (HAR) involves classifying sequences of accelerometer
data together to identify defined movements. Current solutions involve hand
crafting features (thereby requiring an expert of the space to assist), or by
training machine learning models using decision trees.&lt;/p>
&lt;p>Long short term memory (LSTM) models are currently the most powerful type of
recurrent neural networks (RNNs). LSTMs are great at identifying and predicting
sequential information as they take both time and sequence in to account.
However, LSTMs are computationally expensive.&lt;/p>
&lt;h2 id="the-current-state-of-the-art-devises-an-algorithm-that-takes-in-raw-signal-or-visual-data-and-can-identify-patterns-and-sequences-of-movement-1-this-method-is-great-when-working-on-raw-data-streams-but-there-do-exist-better-algorithms-and-models-to-handle-visual-representations-of-movement">The current state of the art devises an algorithm that takes in raw signal or visual data, and can identify patterns and sequences of movement [1]. This method is great when working on raw data streams, but there do exist better algorithms and models to handle visual representations of movement.&lt;/h2>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/advances-in-human-activity-recognition/</description></item><item><title>A summary of Challenges and Opportunities for Autonomous Micro-UAVs in Precision Agriculture by Xu Liu et al.</title><link>https://nsynovic.dev/summaries/challenges-and-opportunities-for-autonomous-micro-uavs-in-precision-agriculture/</link><pubDate>Sat, 18 Feb 2023 13:08:36 -0600</pubDate><guid>https://nsynovic.dev/summaries/challenges-and-opportunities-for-autonomous-micro-uavs-in-precision-agriculture/</guid><description>&lt;h1 id="a-summary-of-challenges-and-opportunities-for-autonomous-micro-uavs-in-precision-agriculture">A summary of &lt;em>Challenges and Opportunities for Autonomous Micro-UAVs in Precision Agriculture&lt;/em>&lt;/h1>
&lt;blockquote>
&lt;p>Xu Liu et al. IEEE Computing Edge, December 2022 DOI [0]&lt;/p>
&lt;/blockquote>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-challenges-and-opportunities-for-autonomous-micro-uavs-in-precision-agriculture">A summary of &lt;em>Challenges and Opportunities for Autonomous Micro-UAVs in Precision Agriculture&lt;/em>&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#uav-hardware-and-autonomy">UAV Hardware and Autonomy&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#uav-platforms-and-autonomy">UAV Platforms and Autonomy&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sensor-configuration">Sensor Configuration&lt;/a>&lt;/li>
&lt;li>&lt;a href="#challenges">Challenges&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#object-detection-and-segmentation">Object Detection and Segmentation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#image-based-2-d">Image-Based (2-D)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#lidar-based-3-d">LiDAR-Based (3-D)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#challenges-1">Challenges&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#robot-localization-and-mapping">Robot Localization and Mapping&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#semantic-localization-and-mapping">Semantic Localization and Mapping&lt;/a>&lt;/li>
&lt;li>&lt;a href="#challenges-2">Challenges&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Unmanned ground and areal vehicles (UGVs and UAVs respectfully) are utilized for
precision agriculture. UGVs can carry a larger payload and can run longer, but
suffer from only being operational within 2D space. UAVs have the benefit of
being able to navigate rougher terrains in 3D space, but suffer from limited
flight times and smaller payloads. This article aims to survey the recent
advances in UAV technologies applied to precision farming and to present
opportunities for improvement.&lt;/p>
&lt;p>There are many agriculture issues that exist in our world today. Over 700
million people are malnourished, 70% of fresh water is utilized by agriculture
domains, and advancements made on micro scales do not scale to the macro
environment. Having more data from autonomous sensors and vehicles will help
improve the realizations of scientific advancements in scale.&lt;/p>
&lt;p>Current UGV technologies suffer from being able to only see points of interest
close to vehicle, they can not survey large areas quickly, and they are unable
to navigate rough agriculture environments (i.e.,, rice fields). UAVs do not
suffer from these drawbacks, however, to work for precision agriculture, UAV
technologies need to work close to crops (under canopy flight), must have
reliable relative coordinate reporting, handle a dynamic environment in PD space
(i.e.,, wind, rocks, hills), and must be able to map dense environments. There
have been some under canopy tests that have been performed to limited success.
However, these were only applied in small scale environments and haven&amp;rsquo;t been
tested in larger environments.&lt;/p>
&lt;h3 id="uav-hardware-and-autonomy">UAV Hardware and Autonomy&lt;/h3>
&lt;p>Current autonomous UAV technologies are available, but their usage is limited.
They currently are reliant upon GPS, which requires an open canopy, making under
canopy flight currently impossible. Additionally, complex tasks such as
segmentation of fruits or trees is not possible at this time.&lt;/p>
&lt;h4 id="uav-platforms-and-autonomy">UAV Platforms and Autonomy&lt;/h4>
&lt;p>Several different autonomous systems have been proposed for under-canopy
autonomous flight.&lt;/p>
&lt;p>These include:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;&amp;hellip; A stereo visual-inertial odometry (VIO) algorithm was used for state
estimation, a 2-D light detection and ranging (LiDAR) mounted on a nodding
gimbal was used for mapping and obstacle avoidance, and a search-based motion
planner was used for motion primitives plans collision-free and dynamically
feasible trajectories,&amp;rdquo; [1]&lt;/li>
&lt;li>A vision based solution that can navigate in both structured and moderately
unstructured environments (i.e., a collapsed building) [2]&lt;/li>
&lt;li>A system of using many UAVs that work together and coordinate through a
simultaneous localization and mapping (SLAM) scheme with loop closure that
utilized trees as landmarks was tested [3], but could fail when operating
within a dense forest&lt;/li>
&lt;/ul>
&lt;p>A limitation with all of these systems so far is that they are unable to work in
long range agricultural missions and they are unable to identify objects in real
time and at scale.&lt;/p>
&lt;h4 id="sensor-configuration">Sensor Configuration&lt;/h4>
&lt;p>Sensors on UAVs are used for both autonomy and for collecting mission specific
data. The most common sensors on UAVs are cameras, inertial measurement units
(IMUs), LiDARs, and global navigation satellite systems (GNSS). These sensors
must be lightweight because multi-rotor UAVs consume 100 - 200 W/kg.&lt;/p>
&lt;p>Cameras and IMUs are great for navigation and obstacle avoidance. However,
cameras are easily susceptible to changes in lightness and darkness. Thus
obstacle avoidance becomes difficult when lighting is patchy.&lt;/p>
&lt;p>LiDAR sensors can be used to reduce this issue, however, current LiDAR
technology is expensive, heavy, and still under much research.&lt;/p>
&lt;p>GNSS technologies (i.e., GPS) allow for geospatial positioning. However, if
there are obstacles in the way, the accuracy decreases. There do exists
optimizations to improve geospatial coordination and positioning, such as GPS
ground stations (DGPS) and real time kinematics (RTK). However, these solutions
must be both real time and reliable to resolve accuracy concerns.&lt;/p>
&lt;h4 id="challenges">Challenges&lt;/h4>
&lt;p>Detection of small obstacles is difficult with conventional camera systems. Thus
a forward facing, solid state LiDAR solution has been proposed to mitigate this.
However, the 360 degree view that LiDAR provides is lost because all of the
LiDAR beams are focused at the front of the device in order to gain resolution.&lt;/p>
&lt;p>Smaller UAVs can be more nimble, however, there is a weight to power and a
weight to flight time concern with these devices.&lt;/p>
&lt;p>Running deep neural network (DNN) algorithms on board a UAV is critical for low
latency, real time data collection, estimation, and understanding. However,
current DNN algorithms are computationally expensive to run. It is predicted
that more efficient algorithms, as well as the usage of AI accelerators, will
help mitigate this problem.&lt;/p>
&lt;h3 id="object-detection-and-segmentation">Object Detection and Segmentation&lt;/h3>
&lt;p>Object detection and segmentation are critical to precise agriculture as plant
or fruit specific data can be captured and acted upon.&lt;/p>
&lt;h4 id="image-based-2-d">Image-Based (2-D)&lt;/h4>
&lt;p>RGB, multi and hyper spectral imaging, thermal, and near-infrared imaging have
been used to perform object detection on plants. Previous methods involved using
K-Means algorithms and SVMs to solve detection and segmentation problems.
Recently, DNN based solutions are becoming more popular and additional sensor
data from the ground is also inputted into these algorithms to provide more
accurate results.&lt;/p>
&lt;h4 id="lidar-based-3-d">LiDAR-Based (3-D)&lt;/h4>
&lt;p>LiDAR based CV solutions are relatively new to the agriculture space. To
represent the problem domain, LiDAR captures data in the forms including a voxel
grid, point clouds, and multi-view and/or spherical images. It has been found
that voxel grid based convolutional neural networks (CNNs) are susceptible to
noise, whereas point clouds are not as affected. It is possible to join LiDAR
point cloud data and a spherical range image together and pass the union of this
data into a CNN to reduce information loss [4].&lt;/p>
&lt;h4 id="challenges-1">Challenges&lt;/h4>
&lt;p>It is difficult to acquire large, high-quality agriculture specific datasets to
train models on object detection and segmentation. Furthermore, occlusion
(e.g.,, not being able to see the plant or fruit) is still a problem that is
trying to be solved.&lt;/p>
&lt;h3 id="robot-localization-and-mapping">Robot Localization and Mapping&lt;/h3>
&lt;p>Mapping refers to the act of creating an understanding of an environment for an
autonomous robot to adhere to. Potential solutions require the input of
knowledge about the structure of the field.&lt;/p>
&lt;h4 id="semantic-localization-and-mapping">Semantic Localization and Mapping&lt;/h4>
&lt;p>Semantic features allows the robot to generate a meaningful map of the
environment and assist in pose estimation. The usage of locating and
representing trees as points of interests has been studied and found to be
useful for identifying local regions.&lt;/p>
&lt;h4 id="challenges-2">Challenges&lt;/h4>
&lt;p>SLAM is able to performing mapping quite well in man made environments. However,
new technologies must be developed to assist with the mapping of natural
environments. Active mapping (where an autonomous agent maps out its environment
in real time) is difficult to do in an agriculture context as fields can be
quite large and contain a dense information mapping.&lt;/p>
&lt;hr>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/challenges-and-opportunities-for-autonomous-micro-uavs-in-precision-agriculture/</description></item><item><title>A summary of Efficient Computer Vision for Embedded Systems by George K. Thiruvathukal and Yung-Hsiang Lu</title><link>https://nsynovic.dev/summaries/efficient-computer-vision-for-embedded-systems/</link><pubDate>Sat, 18 Feb 2023 10:41:18 -0600</pubDate><guid>https://nsynovic.dev/summaries/efficient-computer-vision-for-embedded-systems/</guid><description>&lt;h1 id="a-summary-of-a-summary-of-efficient-computer-vision-for-embedded-systems-0">A summary of &lt;em>A summary of Efficient Computer Vision for Embedded Systems&lt;/em> [0]&lt;/h1>
&lt;blockquote>
&lt;p>George K. Thiruvathukal and Yung-Hsiang Lu; IEEE Computing Edge, December
2022, 2022 &lt;a href="https://doi.org/10.1109/MC.2022.3145677">DOI&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>For the summary of the paper, go to the &lt;a href="#summary">Summary&lt;/a> section of this
article.&lt;/p>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#a-summary-of-a-summary-of-efficient-computer-vision-for-embedded-systems-0">A summary of &lt;em>A summary of Efficient Computer Vision for Embedded Systems&lt;/em> [0]&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#lpcvc">LPCVC&lt;/a>&lt;/li>
&lt;li>&lt;a href="#lpcvc-research">LPCVC Research&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#citations">Citations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;blockquote>
&lt;p>Disclosure: Both George K. Thiruvathukal and Yung-Hsiang Lu are mentors,
colleagues, and friends of mine. Disclosure: I am a student organizer of the
2023 Low Power Computer Vision competition.&lt;/p>
&lt;/blockquote>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Computer Vision (CV) research and development is encouraged through competitions
that measure the accuracy of models for cash prizes. However, as more CV
technologies are being pushed towards the edge, power and computational
efficiency of these models become increasingly more important. Therefore, the
&lt;em>IEEE Low Power Computer Vision Challenge&lt;/em> (LPCVC) [1], formerly the &lt;em>Low
Power Image Recognition Challenge&lt;/em>, was created to encourage researchers to
develop efficient low power solutions.&lt;/p>
&lt;h3 id="lpcvc">LPCVC&lt;/h3>
&lt;blockquote>
&lt;p>&lt;em>Why did you participate in LPCVC?&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>Researchers participate to develop and formalize techniques for running machine
learning on the edge. This could be designing new hardware to accelerate CV
models and/or validating optimization and software techniques developing new CV
models. Additionally, this challenge encourages the discovery of new research
topics to pursue.&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>How is LPCVC relevant to activities in the IEEE Computer Society&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>The development and support of CV research is crucial the Computer Society&amp;rsquo;s
mission. The technical community, &lt;em>Technical Community on Pattern Analysis and
Machine Intelligence&lt;/em> [2], exists to promote the development of research and
solutions to problems surrounding and involving CV. Furthermore, the &lt;em>Computer
Vision and Pattern Recognition&lt;/em> (CVPR) conference [3] is currently IEEE&amp;rsquo;s most
influential conference as ranked by &lt;em>Guide2Research&lt;/em> [4].&lt;/p>
&lt;h3 id="lpcvc-research">LPCVC Research&lt;/h3>
&lt;blockquote>
&lt;p>&lt;em>Why is research in LPCV important?&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>As AI on the edge becomes more ubiquitous and desired by consumers, academic
research my provide industry with potential solutions to implement on the edge.
Furthermore, there exists a hardware challenge alongside the software challenge
of deploying LPCV solutions on edge. Thus hardware focused research must occur
to assist in LPCV optimizations. Hardware devices such as GPUs, CPUs, and Neural
Processing Units (NPUs) need to be designed and optimized (w.r.t hardware and
software) to support CV applications on the edge. Therefore, LPCV research
involves the union of power efficient designs and optimizations of both the
deployment hardware and solution software.&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>Can you describe one (or several) &amp;ldquo;grand challenges&amp;rdquo; using CV; the solutions
will significantly change the world, but are they far beyond today&amp;rsquo;s
technologies?&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>Better smart systems (e.g.,, smart homes, retail, factory, transportation,
farming, etc.) and prediction of natural disasters and phenomenon by utilizing
many data points can be possible through LPCV.&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>If you have unlimited resources, what would you like to see in the area of
LPCV?&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>Researchers in the space are looking for new datasets, challenges, and problem
specific competitions to advance research in LPCV.&lt;/p>
&lt;h2 id="citations">Citations&lt;/h2>
Citations availible at https://nsynovic.dev/summaries/efficient-computer-vision-for-embedded-systems/</description></item></channel></rss>