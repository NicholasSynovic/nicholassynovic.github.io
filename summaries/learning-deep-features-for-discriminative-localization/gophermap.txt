!A summary of Learning Deep Features for Discriminative Localization by Bolei Zhou et al.

Monday, October 24, 2022 Â· 5 minute read

A summary of Learning Deep Features for Discriminative Localization Bolei Zhou et al.; DOI
For the summary of the paper, go to the Summary section of this article.
Table of Contents A summary of Learning Deep Features for Discriminative Localization Table of Contents First Pass Category Context Contributions Second Pass Background Work Motivation Figures, Diagrams, Illustrations, and Graphs Clarity Relevant Work Third Pass Future Directions Summary Summarization Technique Citations First Pass Discussion about the title, abstract, introduction, section and sub-section headings, and conclusion
The paper Learning Deep Features for Discriminative Localization by Bolei Zhou et al. [1] describes using the global average pooling layer of CNNs to not only regularize data, but also to localize objects in an image even if the network wasn&rsquo;t trained for object detection. The authors propose a method for object localization that involves a simple modification to the layer to generate what they call &ldquo;class activation maps&rdquo; (CAMs), which are heatmaps of where the CNN is &ldquo;looking&rdquo; at an image for labeling. The hotter the heatmap, the more focus the CNN is putting on that specific image region.
The authors go into detail as to how one would accomplish this with a weakly-supervised object localization method, and its applications towards deep features for generic localization, fine-grained recognition, and pattern discovery. They conclude with visualizing class specific units.
Their technique accomplishes object localization in a single forward pass on existing CNN models that utilize a global average pooling layer.
Category What type of paper is this work?
This paper is a CNN understanding and technique paper. It discusses a method for understanding what a CNN is looking at as well as expanding the usage of image classifiers for object localization.
Context What other types of papers is the work related to?
This paper is related to works involving object localization, image classification, CNNs, and Deep Learning papers.
Contributions What are the author&rsquo;s main contributions?
The author&rsquo;s main contribution is a method for modifying the global average pooling layer in CNNs to perform object localization in a single forward pass.
Second Pass Background Work What has been done prior to this paper?
There has been work done in utilizing weakly-supervised learning to perform object localization. However, these works either don&rsquo;t evaluate the object localization task, or utilize multiple passes to perform the task.
There has been numerous work that has gone into visualizing what occurs within a CNN. Additionally, there has been work that has looked at the global max pooling layer, however, this work is the first to utilize the global average layer.
Motivation Why should we care about this paper?
We should care about this paper as it provides a methodology of utilizing existing CNNs trained on image classification to perform object localization tasks &ldquo;for free&rdquo;. In other words, this paper presents a methodology for object localization by reusing existing SOTA CNNs.
Figures, Diagrams, Illustrations, and Graphs Are the axes properly labeled? Are results shown with error bars, so that conclusions are statistically significant?
All of the figures and tables are labelled clearly, have detailed captions, and make sense with respect to the paper.
Clarity Is the paper well written?
The paper is well written.
Relevant Work Mark relevant work for review
The following relevant work can be found in the Citations section of this article.
Self-taught object localization with deep networks [2] Weakly supervised object localization with multi-fold multiple instance learning [3] Learning and transferring mid-level image representations using convolutional neural networks [4] Is object localization for free? weakly-supervised learning with convolutional neural networks [5] Visualizing and understanding convolutional networks [6] Object detectors emerge in deep scene cnns [7] Network in network [8] Going deeper with convolutions [9] Third Pass This section can only be complete after a virtual re-implementation of the paper
Future Directions My own proposed future directions for the work
I would love to take this work and apply it to my current research in low powered computer vision. By utilizing larger networks to localize where in a static scene the object of interest is most likely to be in (for example, a static video of a bird sitting on a wire), I can pass in this mapping into a CNN to specifically be interested in that region of the video/ image. Additionally, by figuring out where a larger CNN is localizing data, I can then mask out any cold area of the image prior to analysis by a smaller CNN.
Summary A summary of the paper
The paper Learning Deep Features for Discriminative Localization by Bolei Zhou et al. [1] discusses a weakly supervised method of performing object localization on existing CNN models. Their method involves replacing the fully connected layer at the end of a CNN performing image classifcation, with a global average pooling layer into a softmax layer. This is so that the models original functionality is not cut from the new model. However, the global average pooling layer is modified so that a heatmap can be extracted focusing on what the CNN is focussing on prior to labelling the image.
Previous work involved the usage of weakly supervised CNNs, but relied on global max pooling. Additional work utilized deconvolutional layers to perform a similar task.
Summarization Technique This paper was summarized using the technique proposed by S. Keshav in his work How to Read a Paper [0].
Citations 

h0. https://doi.org/10.1145/1273445.1273458	URL:https://doi.org/10.1145/1273445.1273458

h1. http://arxiv.org/abs/1512.04150	URL:http://arxiv.org/abs/1512.04150

h2. https://doi.org/10.1109/WACV.2016.7477688	URL:https://doi.org/10.1109/WACV.2016.7477688

h3. https://doi.org/10.1109/TPAMI.2016.2535231	URL:https://doi.org/10.1109/TPAMI.2016.2535231

h4. https://openaccess.thecvf.com/content_cvpr_2014/html/Oquab_Learning_and_Transferring_2014_CVPR_paper.html	URL:https://openaccess.thecvf.com/content_cvpr_2014/html/Oquab_Learning_and_Transferring_2014_CVPR_paper.html

h5. https://openaccess.thecvf.com/content_cvpr_2015/html/Oquab_Is_Object_Localization_2015_CVPR_paper.html	URL:https://openaccess.thecvf.com/content_cvpr_2015/html/Oquab_Is_Object_Localization_2015_CVPR_paper.html

h6. https://doi.org/10.1007/978-3-319-10590-1_53	URL:https://doi.org/10.1007/978-3-319-10590-1_53

h7. https://arxiv.org/abs/1412.6856	URL:https://arxiv.org/abs/1412.6856

h8. https://arxiv.org/abs/1312.4400	URL:https://arxiv.org/abs/1312.4400

h9. https://doi.org/10.48550/arXiv.1409.4842	URL:https://doi.org/10.48550/arXiv.1409.4842

.
