!A summary of ImageNet Classification with Deep Convolutional Neural Networks by Krizhevsky et al.

Thursday, September 29, 2022 Â· 3 minute read

A summary of ImageNet Classification with Deep Convolutional Neural Networks Krizhevsky et al.; https://doi.org/10.1145/3065386
For the summary of the paper, go to the Summary section of this article.
Table of Contents A summary of ImageNet Classification with Deep Convolutional Neural Networks Table of Contents First Pass Category Context Contributions Second Pass Background Work Motivation Figures, Diagrams, Illustrations, and Graphs Clarity Relevant Work Third Pass Author Assumptions Correctness Discussion of the Proofs How Would I Present the Idea(s) Future Directions Summary Summarization Technique Citations First Pass Discussion about the title, abstract, introduction, section and sub-section headings, and conclusion
The paper ImageNet Classification with Deep Convolutional Neural Networks by Krizhevsky et al. discusses the AlexNet model and its architecture as well as its SOTA achievements in the 2012 ImageNet Challenge. The difference between AlexNet and other contestants was that the model relies on GPU training to train the convulational neural network model. By utilizing the GPU, training time can be accelerated significatnly more than what was previously possible. Their major contributions is that a large, deep convulational neural network is capable of achieving record-breaking resuls via supervised learning. They did not utilize unsupervised pre-training, but the authors suspect that it would improve the accuracy of the model.
Category What type of paper is this work?
This is a computer vision model evaluation and architecture paper.
Context What other types of papers is the work related to?
This paper is similar to others that have published about SOTA results from the ImageNet Challenge.
Contributions What are the author&rsquo;s main contributions?
Their main contributions were that training on GPUs allows for accelerated training, that large and deep convulutional neural networks are effective at clasifying images, and that removing layers does decrease the performance of models. Therefore, a larger, deeper model is applicable.
Second Pass Background Work What has been done prior to this paper?
Previous work on designing convulational neural networks and architectures. However, they were bounded by not being particularly deep.
Motivation Why should we care about this paper?
Because it is one of the key papers that demonstrates that large, deep, convulational neural networks are effective for image classification. As well as providing evidence that training on GPUs is not only effective but recommended for optimal performance.
Figures, Diagrams, Illustrations, and Graphs Are the axes properly labeled? Are results shown with error bars, so that conclusions are statistically significant?
Nearly all of the figures are designed well, with the exception of Figure 2. Figure 2 is the model architecture of AlexNet. This figure suffers from information density and a three dimensional design which makes it hard to determin what is going on and in what dimension are images being manipulated.
Clarity Is the paper well written?
Relevant Work Mark relevant work for review
The following relevant work can be found in the Citations section of this article.
Third Pass This section can only be complete after a virtual re-implementation of the paper
Author Assumptions What assumptions does the author(s) make? Are they justified assumptions?
Correctness Do the assumptions seem valid?
Discussion of the Proofs How Would I Present the Idea(s) Future Directions My own proposed future directions for the work
Summary A summary of the paper
Summarization Technique This paper was summarized using the technique proposed by S. Keshav in his work How to Read a Paper [0].
Citations 

h0. https://doi.org/10.1145/1273445.1273458	URL:https://doi.org/10.1145/1273445.1273458

.
