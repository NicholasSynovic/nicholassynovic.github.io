---
title: A summary of Deep Learning by Yann LeCun et al,
description: Posted in Nature, 2015
summary: Posted in Nature, 2015

categories: [summary, Pattern recognition, decision tree, decision forest, stochastic
      discrimination, decision combination, classifier combination, multiple-classifier
      system, bootstrapping, Nature, 2015]
citations: [https://doi.org/10.1145/1273445.1273458, https://doi.org/10.1038/nature14539]

draft: false

date: 2022-11-08T12:55:10-06:00
featured_image: ''
include_toc: true
markup: md
outputs: []
show_comments: false
toc: true
show_reading_time: true
---

# A summary of *Deep Learning*

> Yann LeCunn Nature, 2015 [DOI](https://doi.org/10.1038/nature14539)

For the summary of the paper, go to the [Summary](#summary) section of this
article.

## Table of Contents

- [A summary of *Deep Learning*](#a-summary-of-deep-learning)
  - [Table of Contents](#table-of-contents)
  - [First Pass](#first-pass)
    - [Problem](#problem)
    - [Motivation](#motivation)
    - [Category](#category)
    - [Context](#context)
    - [Contributions](#contributions)
  - [Second Pass](#second-pass)
    - [Background Work](#background-work)
    - [Figures, Diagrams, Illustrations, and Graphs](#figures-diagrams-illustrations-and-graphs)
    - [Clarity](#clarity)
    - [Relevant Work](#relevant-work)
    - [Methodology](#methodology)
    - [Author Assumptions](#author-assumptions)
      - [Correctness](#correctness)
    - [Future Directions](#future-directions)
    - [Open Questions](#open-questions)
    - [Author Feedback](#author-feedback)
  - [Summary](#summary)
  - [Summarization Technique](#summarization-technique)
  - [Citations](#citations)

______________________________________________________________________

## First Pass

> Read the title, abstract, introduction, section and sub-section headings, and
> conclusion

### Problem

> What is the problem addressed in the paper?

This paper discusses the usage of deep learning (DL) models and how they have
led to improvements in speech recognition, visual object recognition, object
detection, drug discovery, and genomics. It talks about how these models are
created, what type of models are typically applied to what domains, and the
usage of the backpropogation algorithm to train the model. Additionally, a
discussion about the usage of Recurent Neural Networks (RNNs) and their benefits
is had.

### Motivation

> Why should we care about this paper?

We should care about this paper as it is a review of different DL techniques for
different problem domains.

### Category

> What type of paper is this work?

This paper is a literary review paper.

### Context

> What other *types* of papers is the work related to?

It is closest related to papers that summarize a body of literature for the
purposes of understanding what the current SOTA techniques for a problem are.

### Contributions

> What are the author's main contributions?

Thier main contribution is a discussion of DL, its usages, RNNs, and a general
summary of the SOTA DL techniques for different problem domains.

______________________________________________________________________

## Second Pass

> A proper read through of the paper is required to answer this

### Background Work

> What has been done prior to this paper?

Work has been done to develop DL and RNN techniques.

### Figures, Diagrams, Illustrations, and Graphs

> Are the axes properly labeled? Are results shown with error bars, so that
> conclusions are statistically significant?

All of the figures are clear and easy to understand.

### Clarity

> Is the paper well written?

This paper is well written.

### Relevant Work

> Mark relevant work for review

The following relevant work can be found in the [Citations](#citations) section
of this article.

### Methodology

> What methodology did the author's use to validate their contributions?

The author's of this paper reviewed literary sources for examples and usage of
DL and RNN techniques applied to different problem domains.

### Author Assumptions

> What assumptions does the author(s) make? Are they justified assumptions?

The author's assume that unsupervised learning will become far more important in
the future than supervised learning.

#### Correctness

> Do the assumptions seem valid?

Potentially. Unsupervised learning presents problems and challenges not explored
in this paper, and is therfore treated as the next logical evolution of
techniques, rather than a series of unknowns and problems that need to be solved
first.

### Future Directions

> My own proposed future directions for the work

I'd like to implement the different DL techniques to the suggested problem
domains presented in this paper.

### Open Questions

> What open questions do I have about the work?

Why wasn't a discussion about Generative Adversarial Networks (GANs) not had in
this work? What are the performance differences of the presented loss functions?

### Author Feedback

> What feedback would I give to the authors?

Overall, a pretty good paper. A follow up paper on unsupervised learning would
be nice to read.

______________________________________________________________________

## Summary

> A summary of the paper

______________________________________________________________________

## Summarization Technique

This paper was summarized using a modified technique proposed by S. Keshav in
his work *How to Read a Paper* \[0\].

## Citations
